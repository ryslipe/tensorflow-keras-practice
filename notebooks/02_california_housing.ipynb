{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### California Housing Regression Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bunch object which is a special sklearn object\n",
    "It behaves like a dictionary (housing['data'], housing['target']).\n",
    "\n",
    "Contains multiple attributes:\n",
    "\n",
    "housing.data → The actual housing feature data (NumPy array).\n",
    "\n",
    "housing.target → The target values (median house price).\n",
    "\n",
    "housing.feature_names → The names of each feature.\n",
    "\n",
    "housing.DESCR → Description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split of housing data which is a numpy array\n",
    "X_train_full, X_test, y_train_full, y_test= train_test_split(housing.data, housing.target, test_size=0.25, random_state= 42)\n",
    "\n",
    "# make a validation set for the compiling\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6934 - val_loss: 0.5099\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4627\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4253 - val_loss: 0.5128\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.6209\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.4936\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.4637\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4414\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.4322\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4377\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.4274\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.4268\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4319\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4367\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4263\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.4228\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4226\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.4268\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.4264\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.4182\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.4293\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.4153\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.4173\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.4174\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.4406\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4252\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.4168\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.4167\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.4237\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4131\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.4123\n"
     ]
    }
   ],
   "source": [
    "# fit the model save as history\n",
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "# make fake new houses\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6190179],\n",
       "       [1.7084866],\n",
       "       [3.0323572]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare them\n",
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonsequential Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example is when the input layer connects all or part of the inputs directly to the output layer so that the neural network can learn both deep patterns and simple patterns. This is because the deep patterns are learned going the sequential route and the simple patterns are caught by jumping to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonsequential build\n",
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "# pass the input to this hidden layer with 30 neurons\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "# pass the output from the first hidden layer to this hidden layer\n",
    "hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n",
    "# concatenate the input and the ouput of the second hidden layer\n",
    "concat = keras.layers.Concatenate()([input_, hidden_2])\n",
    "# pass in the result of the concatenation to this output layer\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 30)           270         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           930         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 38)           0           ['input_2[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            39          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile this model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1412 - val_loss: 1.5670\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9188 - val_loss: 0.7416\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6418 - val_loss: 0.6481\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6025 - val_loss: 0.6264\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5751 - val_loss: 0.6091\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5519 - val_loss: 0.5919\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5328 - val_loss: 0.5672\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5160 - val_loss: 0.5500\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5007 - val_loss: 0.5406\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4882 - val_loss: 0.5233\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4764 - val_loss: 0.5172\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4669 - val_loss: 0.5073\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4583 - val_loss: 0.5021\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4504 - val_loss: 0.4939\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4437 - val_loss: 0.4898\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4375 - val_loss: 0.4841\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4792\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4760\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4226 - val_loss: 0.4741\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4184 - val_loss: 0.4687\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 961us/step - loss: 0.4903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4903166592121124"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mse on testing\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 128ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.56534386],\n",
       "       [1.7663002 ],\n",
       "       [2.8565946 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting the Wide and Deep Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can send some data only through the wide path for the simple relationships and then send a different subset through the deep path to learn the more complex relationships. Often times we may want the features to overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting the deep and wide paths\n",
    "\n",
    "# create input A for the wide path (wont go through all layers)\n",
    "# takes shape = [5] for 5 features\n",
    "input_A = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "# create input B which goes the deep path and has 6 features\n",
    "input_B = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n",
    "# concatenate layer takes the wide path and output from deep path\n",
    "concat = keras.layers.Concatenate()([input_A, hidden_2])\n",
    "# single output for house price\n",
    "output = keras.layers.Dense(1, name = 'ouput')(concat)\n",
    "\n",
    "# make the model\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compile this model it is the same process but when we fit it we have to fit it to the two subsets. This means we first need to make the two subsets. We will also need to make the \"new\" data which is just the first three rows of the data that have already been reshaped.\n",
    "\n",
    "Input A uses the first 5 features and Input B uses the last 6 so there is some overlap here. Both subsets will use features 2, 3, 4 and 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X train and valid sets for each subset\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "\n",
    "# create validation for each \n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "\n",
    "# create the correct test data\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "\n",
    "\n",
    "# this is for making the predictions later\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = keras.optimizers.SGD(learning_rate = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show both ways to call model.fit with multiple inputs. We can pass them as a dictionary or a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1374 - val_loss: 0.8561\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8008 - val_loss: 0.7111\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7005 - val_loss: 0.6522\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6532 - val_loss: 0.6202\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6207 - val_loss: 0.5972\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5954 - val_loss: 0.5772\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.5603\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5550 - val_loss: 0.5471\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5386 - val_loss: 0.5345\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5238 - val_loss: 0.5230\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5106 - val_loss: 0.5158\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4990 - val_loss: 0.5091\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4889 - val_loss: 0.5024\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4798 - val_loss: 0.4945\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4722 - val_loss: 0.4941\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4895\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4859\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4538 - val_loss: 0.4839\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4490 - val_loss: 0.4817\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4448 - val_loss: 0.4793\n"
     ]
    }
   ],
   "source": [
    "history = model.fit({'wide_input': X_train_A, 'deep_input': X_train_B}, y_train, epochs = 20,\n",
    "                     validation_data = ({'wide_input': X_valid_A, 'deep_input': X_valid_B}, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0847 - val_loss: 0.8919\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7489 - val_loss: 0.6893\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6556 - val_loss: 0.6444\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6142 - val_loss: 0.6057\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5821 - val_loss: 0.5811\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5545 - val_loss: 0.5594\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5312 - val_loss: 0.5431\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5289\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4958 - val_loss: 0.5196\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4831 - val_loss: 0.5101\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4731 - val_loss: 0.4997\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4646 - val_loss: 0.4947\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4579 - val_loss: 0.4884\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4522 - val_loss: 0.4832\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4477 - val_loss: 0.4786\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4783\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4402 - val_loss: 0.4757\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4373 - val_loss: 0.4741\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4344 - val_loss: 0.4716\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4703\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4298 - val_loss: 0.4679\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4275 - val_loss: 0.4653\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4257 - val_loss: 0.4655\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.4636\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4223 - val_loss: 0.4626\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4639\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4191 - val_loss: 0.4647\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4180 - val_loss: 0.4598\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 0.4585\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4152 - val_loss: 0.4599\n"
     ]
    }
   ],
   "source": [
    "# create the history \n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs = 30,\n",
    "                    validation_data = ((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4818\n"
     ]
    }
   ],
   "source": [
    "# testing data\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is often the case, the testing data performs slightly worse than the validation data but not by much so it is not overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48181331157684326"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6114548],\n",
       "       [1.9770505],\n",
       "       [2.761712 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we may have to take multiple inputs. If we are trying to locate and classify the main object in a picture it is a regression task to find the coordinates of the objects center along with the width and height, and a classification task.\n",
    "\n",
    "We can also have a single neural network responsible for many different individual tasks such as a multiclass classification network where output 1 determines the center of an image and output 2 determines the facial expression.\n",
    "\n",
    "We can also add an auxilary output as a regularization technique. This will avoid the concatenation which makes the model learn from the neural network without being put in a layer wiht the inputs at the end (pg. 312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding auxilary output\n",
    "input_A = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "input_B = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "\n",
    "# input_B goes deep\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n",
    "\n",
    "# input A jumps here\n",
    "concat = keras.layers.concatenate([input_A, hidden_2])\n",
    "# main output is deep and wide inputs\n",
    "output = keras.layers.Dense(1, name = 'main_output')(concat)\n",
    "\n",
    "# splits away from concat layer after the hidden layer 2\n",
    "aux_output = keras.layers.Dense(1, name = 'aux_output')(hidden_2)\n",
    "\n",
    "# create model with two inputs and two outputs\n",
    "model = keras.models.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output is added up with their own loss function at the end of training. Since the auxilary output is just used for regularization we want to set wieghts to these different losses which is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.SGD(learning_rate=1e-3), loss = ['mse', 'mse'], loss_weights=[0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I used both the dictionary naming convention when fitting the model and also the list convention. Your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6664 - main_output_loss: 2.4374 - aux_output_loss: 4.7277 - val_loss: 1.2146 - val_main_output_loss: 0.9676 - val_aux_output_loss: 3.4375\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0694 - main_output_loss: 0.8727 - aux_output_loss: 2.8395 - val_loss: 0.8960 - val_main_output_loss: 0.7520 - val_aux_output_loss: 2.1912\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8668 - main_output_loss: 0.7435 - aux_output_loss: 1.9759 - val_loss: 0.7884 - val_main_output_loss: 0.6887 - val_aux_output_loss: 1.6853\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7789 - main_output_loss: 0.6857 - aux_output_loss: 1.6170 - val_loss: 0.7328 - val_main_output_loss: 0.6492 - val_aux_output_loss: 1.4855\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7294 - main_output_loss: 0.6481 - aux_output_loss: 1.4613 - val_loss: 0.6964 - val_main_output_loss: 0.6180 - val_aux_output_loss: 1.4014\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6965 - main_output_loss: 0.6200 - aux_output_loss: 1.3853 - val_loss: 0.6748 - val_main_output_loss: 0.5993 - val_aux_output_loss: 1.3541\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6718 - main_output_loss: 0.5978 - aux_output_loss: 1.3376 - val_loss: 0.6571 - val_main_output_loss: 0.5831 - val_aux_output_loss: 1.3239\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6516 - main_output_loss: 0.5793 - aux_output_loss: 1.3032 - val_loss: 0.6474 - val_main_output_loss: 0.5750 - val_aux_output_loss: 1.2990\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6350 - main_output_loss: 0.5640 - aux_output_loss: 1.2740 - val_loss: 0.6334 - val_main_output_loss: 0.5619 - val_aux_output_loss: 1.2770\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6203 - main_output_loss: 0.5504 - aux_output_loss: 1.2492 - val_loss: 0.6234 - val_main_output_loss: 0.5530 - val_aux_output_loss: 1.2564\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6071 - main_output_loss: 0.5385 - aux_output_loss: 1.2252 - val_loss: 0.6148 - val_main_output_loss: 0.5456 - val_aux_output_loss: 1.2368\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5959 - main_output_loss: 0.5283 - aux_output_loss: 1.2038 - val_loss: 0.6074 - val_main_output_loss: 0.5396 - val_aux_output_loss: 1.2174\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5852 - main_output_loss: 0.5189 - aux_output_loss: 1.1820 - val_loss: 0.6004 - val_main_output_loss: 0.5339 - val_aux_output_loss: 1.1989\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5758 - main_output_loss: 0.5106 - aux_output_loss: 1.1622 - val_loss: 0.5965 - val_main_output_loss: 0.5316 - val_aux_output_loss: 1.1810\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5669 - main_output_loss: 0.5029 - aux_output_loss: 1.1422 - val_loss: 0.5892 - val_main_output_loss: 0.5254 - val_aux_output_loss: 1.1633\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5588 - main_output_loss: 0.4961 - aux_output_loss: 1.1232 - val_loss: 0.5845 - val_main_output_loss: 0.5221 - val_aux_output_loss: 1.1454\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5516 - main_output_loss: 0.4902 - aux_output_loss: 1.1043 - val_loss: 0.5771 - val_main_output_loss: 0.5159 - val_aux_output_loss: 1.1280\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5443 - main_output_loss: 0.4841 - aux_output_loss: 1.0862 - val_loss: 0.5762 - val_main_output_loss: 0.5167 - val_aux_output_loss: 1.1110\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5383 - main_output_loss: 0.4795 - aux_output_loss: 1.0682 - val_loss: 0.5696 - val_main_output_loss: 0.5113 - val_aux_output_loss: 1.0942\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5321 - main_output_loss: 0.4744 - aux_output_loss: 1.0511 - val_loss: 0.5652 - val_main_output_loss: 0.5084 - val_aux_output_loss: 1.0768\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], \n",
    "    [y_train, y_train],\n",
    "    epochs=20, \n",
    "    validation_data=(\n",
    "    [X_valid_A, X_valid_B], \n",
    "    [y_valid, y_valid]\n",
    ")\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.5265 - main_output_loss: 0.4702 - aux_output_loss: 1.0337 - val_loss: 0.5601 - val_main_output_loss: 0.5045 - val_aux_output_loss: 1.0604\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5210 - main_output_loss: 0.4659 - aux_output_loss: 1.0168 - val_loss: 0.5565 - val_main_output_loss: 0.5023 - val_aux_output_loss: 1.0445\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5158 - main_output_loss: 0.4620 - aux_output_loss: 1.0003 - val_loss: 0.5529 - val_main_output_loss: 0.5000 - val_aux_output_loss: 1.0289\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5112 - main_output_loss: 0.4587 - aux_output_loss: 0.9844 - val_loss: 0.5471 - val_main_output_loss: 0.4953 - val_aux_output_loss: 1.0128\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5068 - main_output_loss: 0.4555 - aux_output_loss: 0.9684 - val_loss: 0.5445 - val_main_output_loss: 0.4942 - val_aux_output_loss: 0.9978\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5023 - main_output_loss: 0.4523 - aux_output_loss: 0.9524 - val_loss: 0.5380 - val_main_output_loss: 0.4886 - val_aux_output_loss: 0.9829\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4988 - main_output_loss: 0.4500 - aux_output_loss: 0.9379 - val_loss: 0.5343 - val_main_output_loss: 0.4861 - val_aux_output_loss: 0.9681\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4947 - main_output_loss: 0.4471 - aux_output_loss: 0.9231 - val_loss: 0.5317 - val_main_output_loss: 0.4848 - val_aux_output_loss: 0.9537\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4915 - main_output_loss: 0.4452 - aux_output_loss: 0.9083 - val_loss: 0.5286 - val_main_output_loss: 0.4828 - val_aux_output_loss: 0.9404\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4876 - main_output_loss: 0.4424 - aux_output_loss: 0.8949 - val_loss: 0.5299 - val_main_output_loss: 0.4857 - val_aux_output_loss: 0.9274\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4852 - main_output_loss: 0.4412 - aux_output_loss: 0.8811 - val_loss: 0.5239 - val_main_output_loss: 0.4805 - val_aux_output_loss: 0.9146\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4821 - main_output_loss: 0.4392 - aux_output_loss: 0.8680 - val_loss: 0.5220 - val_main_output_loss: 0.4797 - val_aux_output_loss: 0.9024\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4791 - main_output_loss: 0.4373 - aux_output_loss: 0.8551 - val_loss: 0.5207 - val_main_output_loss: 0.4796 - val_aux_output_loss: 0.8909\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4761 - main_output_loss: 0.4353 - aux_output_loss: 0.8431 - val_loss: 0.5161 - val_main_output_loss: 0.4758 - val_aux_output_loss: 0.8789\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4734 - main_output_loss: 0.4337 - aux_output_loss: 0.8306 - val_loss: 0.5134 - val_main_output_loss: 0.4741 - val_aux_output_loss: 0.8675\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4712 - main_output_loss: 0.4326 - aux_output_loss: 0.8186 - val_loss: 0.5118 - val_main_output_loss: 0.4734 - val_aux_output_loss: 0.8570\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4686 - main_output_loss: 0.4310 - aux_output_loss: 0.8068 - val_loss: 0.5103 - val_main_output_loss: 0.4730 - val_aux_output_loss: 0.8469\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4661 - main_output_loss: 0.4295 - aux_output_loss: 0.7956 - val_loss: 0.5098 - val_main_output_loss: 0.4735 - val_aux_output_loss: 0.8369\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4641 - main_output_loss: 0.4285 - aux_output_loss: 0.7850 - val_loss: 0.5099 - val_main_output_loss: 0.4745 - val_aux_output_loss: 0.8285\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4619 - main_output_loss: 0.4271 - aux_output_loss: 0.7747 - val_loss: 0.5050 - val_main_output_loss: 0.4701 - val_aux_output_loss: 0.8186\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4598 - main_output_loss: 0.4258 - aux_output_loss: 0.7649 - val_loss: 0.5055 - val_main_output_loss: 0.4716 - val_aux_output_loss: 0.8104\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - main_output_loss: 0.4248 - aux_output_loss: 0.7549 - val_loss: 0.5060 - val_main_output_loss: 0.4730 - val_aux_output_loss: 0.8027\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4557 - main_output_loss: 0.4234 - aux_output_loss: 0.7459 - val_loss: 0.5036 - val_main_output_loss: 0.4712 - val_aux_output_loss: 0.7949\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4539 - main_output_loss: 0.4224 - aux_output_loss: 0.7368 - val_loss: 0.5005 - val_main_output_loss: 0.4686 - val_aux_output_loss: 0.7874\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4520 - main_output_loss: 0.4213 - aux_output_loss: 0.7285 - val_loss: 0.5001 - val_main_output_loss: 0.4689 - val_aux_output_loss: 0.7807\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4505 - main_output_loss: 0.4205 - aux_output_loss: 0.7205 - val_loss: 0.4990 - val_main_output_loss: 0.4684 - val_aux_output_loss: 0.7744\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4486 - main_output_loss: 0.4193 - aux_output_loss: 0.7124 - val_loss: 0.4980 - val_main_output_loss: 0.4679 - val_aux_output_loss: 0.7687\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4472 - main_output_loss: 0.4184 - aux_output_loss: 0.7059 - val_loss: 0.4975 - val_main_output_loss: 0.4680 - val_aux_output_loss: 0.7630\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4455 - main_output_loss: 0.4174 - aux_output_loss: 0.6984 - val_loss: 0.4988 - val_main_output_loss: 0.4699 - val_aux_output_loss: 0.7585\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4439 - main_output_loss: 0.4163 - aux_output_loss: 0.6919 - val_loss: 0.4950 - val_main_output_loss: 0.4664 - val_aux_output_loss: 0.7527\n"
     ]
    }
   ],
   "source": [
    "# since we didnt restart the model this is actually going til the 50th epoch\n",
    "history = model.fit(\n",
    "    {'wide_input': X_train_A, 'deep_input': X_train_B}, \n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=30, \n",
    "    validation_data=(\n",
    "        {'wide_input': X_valid_A, 'deep_input': X_valid_B}, \n",
    "        {'main_output': y_valid, 'aux_output': y_valid}\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5177 - main_output_loss: 0.4908 - aux_output_loss: 0.7599\n"
     ]
    }
   ],
   "source": [
    "# we have two losses now\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5177099108695984"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4907994568347931"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7599028944969177"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    }
   ],
   "source": [
    "# now have two predictions\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0599136],\n",
       "       [1.700481 ],\n",
       "       [2.0774426]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67476404],\n",
       "       [2.0080202 ],\n",
       "       [2.7493432 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOP Model Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this set up we use super() since it is a subclass of keras.models.Model so it inherits things like .fit(), .evaluate()...In the initialization we create our layers and in the call function we create the computations. This is very similar to the forward pass we did in the micrograd implementation. The method must be called call.\n",
    "\n",
    "**when using this technique, the dictionary naming of inputs and outputs does not work, use a tuple.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This added flexiblility includes putting for loops or other operations in the call method but we cannot save or clone it and the summary() method only shows the list of layers so stick to functional if you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        # keras has an output attribute so rename main_output\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0047 - output_1_loss: 1.8954 - output_2_loss: 2.9883 - val_loss: 1.0551 - val_output_1_loss: 0.9474 - val_output_2_loss: 2.0241\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8979 - output_1_loss: 0.7998 - output_2_loss: 1.7806 - val_loss: 0.7942 - val_output_1_loss: 0.7163 - val_output_2_loss: 1.4956\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7122 - output_1_loss: 0.6397 - output_2_loss: 1.3643 - val_loss: 0.7286 - val_output_1_loss: 0.6697 - val_output_2_loss: 1.2590\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6511 - output_1_loss: 0.5917 - output_2_loss: 1.1852 - val_loss: 0.6821 - val_output_1_loss: 0.6291 - val_output_2_loss: 1.1595\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6111 - output_1_loss: 0.5574 - output_2_loss: 1.0941 - val_loss: 0.6496 - val_output_1_loss: 0.5995 - val_output_2_loss: 1.1007\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5812 - output_1_loss: 0.5305 - output_2_loss: 1.0375 - val_loss: 0.6213 - val_output_1_loss: 0.5726 - val_output_2_loss: 1.0596\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5579 - output_1_loss: 0.5094 - output_2_loss: 0.9950 - val_loss: 0.6019 - val_output_1_loss: 0.5546 - val_output_2_loss: 1.0273\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5395 - output_1_loss: 0.4926 - output_2_loss: 0.9617 - val_loss: 0.5858 - val_output_1_loss: 0.5400 - val_output_2_loss: 0.9980\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5250 - output_1_loss: 0.4796 - output_2_loss: 0.9330 - val_loss: 0.5708 - val_output_1_loss: 0.5263 - val_output_2_loss: 0.9713\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5132 - output_1_loss: 0.4694 - output_2_loss: 0.9070 - val_loss: 0.5623 - val_output_1_loss: 0.5192 - val_output_2_loss: 0.9504\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-3), loss = ['mse', 'mse'], loss_weights=[0.9, 0.1])\n",
    "\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Restoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember this only works with the sequential or functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.7118 - val_loss: 0.8984\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7521 - val_loss: 0.6765\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6540 - val_loss: 0.6435\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6215 - val_loss: 0.6238\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5979 - val_loss: 0.6033\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5773 - val_loss: 0.5860\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5594 - val_loss: 0.5697\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5435 - val_loss: 0.5611\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.5458\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5153 - val_loss: 0.5362\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5032 - val_loss: 0.5263\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4924 - val_loss: 0.5194\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4833 - val_loss: 0.5109\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4751 - val_loss: 0.5051\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4679 - val_loss: 0.4994\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4969\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4914\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4507 - val_loss: 0.4871\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4851\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.4804\n",
      "162/162 [==============================] - 0s 922us/step - loss: 0.4995\n"
     ]
    }
   ],
   "source": [
    "# make a sequential model to be saved\n",
    "\n",
    "# when using input_shape batch size comes first so we start at 1\n",
    "# same as input_shape = [8] because X_train has 8 features\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = keras.optimizers.SGD(1e-3), loss = 'mse')\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022296201CF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 212ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.95043904],\n",
       "       [1.4848106 ],\n",
       "       [2.608714  ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions from saved model\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times training can last a long time so we should not only save the model at the end of training but also save checkpoints at regular intervals during training just incase the computer crashes. We should also tell the fit() method to save checkpoints. This is done using callbacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4385\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4353\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4323\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4297\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4246\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4227\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4206\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4185\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4168\n"
     ]
    }
   ],
   "source": [
    "# create callback\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "\n",
    "# this model will be saved at the end of each epoch\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent training for too long and overfitting we can use early stopping. This is done with save_best_only = True. The model will still train for all epochs but not every epoch will be saved (unless it gets better each time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4150 - val_loss: 0.4596\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4136 - val_loss: 0.4583\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4119 - val_loss: 0.4570\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4102 - val_loss: 0.4567\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4091 - val_loss: 0.4552\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4076 - val_loss: 0.4536\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4061 - val_loss: 0.4535\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4050 - val_loss: 0.4508\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4035 - val_loss: 0.4516\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.4500\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4011 - val_loss: 0.4491\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4001 - val_loss: 0.4483\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3991 - val_loss: 0.4479\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4469\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3968 - val_loss: 0.4454\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3959 - val_loss: 0.4450\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3948 - val_loss: 0.4449\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.4436\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3929 - val_loss: 0.4432\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3920 - val_loss: 0.4424\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be combined with the early stopping callback which interrupts training when it measures no progress on the validation data after a certain number of \"patience\" rounds. When we say patience = 5 it will go for 5 more epochs to check for an improvement. The restore best weights argument means after those 5 that did not improve we will go back to the one where it was improving.\n",
    "\n",
    "The following code combines both callbacks. Early stopping is used so that we do not train for 100 epochs if we do not have to and the old callback saves the best model. We did 56 epochs instead of 100 since we used early stopping. It is important to know that since we used save_best_only = True, the last epoch may not be the one that gets saved. This is because we do 5 patience rounds so the old callback already saved that model before training did not improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4420\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4414\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4397\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3886 - val_loss: 0.4399\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3877 - val_loss: 0.4394\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4399\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3862 - val_loss: 0.4372\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3854 - val_loss: 0.4386\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4372\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.4370\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3833 - val_loss: 0.4377\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4360\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4350\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4346\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4354\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3801 - val_loss: 0.4334\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3794 - val_loss: 0.4356\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3793 - val_loss: 0.4327\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4345\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3780 - val_loss: 0.4330\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3771 - val_loss: 0.4328\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3763 - val_loss: 0.4330\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.4322\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.4315\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3749 - val_loss: 0.4317\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 0.4342\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4319\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3733 - val_loss: 0.4306\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.4313\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4298\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3715 - val_loss: 0.4327\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4304\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4286\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3705 - val_loss: 0.4290\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3700 - val_loss: 0.4291\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3697 - val_loss: 0.4285\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.4283\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.4290\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3685 - val_loss: 0.4280\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.4281\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3673 - val_loss: 0.4291\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3671 - val_loss: 0.4282\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3667 - val_loss: 0.4281\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3665 - val_loss: 0.4276\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4266\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3654 - val_loss: 0.4278\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.4262\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4266\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.4261\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.4288\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3642 - val_loss: 0.4260\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.4262\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.4274\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3625 - val_loss: 0.4263\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.4265\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.4262\n"
     ]
    }
   ],
   "source": [
    "# early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make a class to implement a custom callback. This custom callback keeps track of the ratio between the training and validation error to detect overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f\"\\nval/train: {logs['val_loss'] / logs['loss']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/363 [..............................] - ETA: 2s - loss: 0.2624WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0003s vs `on_train_batch_begin` time: 0.0005s). Check your callbacks.\n",
      "318/363 [=========================>....] - ETA: 0s - loss: 0.3597\n",
      "val/train: 1.17\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.4250\n",
      "Epoch 2/5\n",
      "315/363 [=========================>....] - ETA: 0s - loss: 0.3585\n",
      "val/train: 1.18\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4264\n",
      "Epoch 3/5\n",
      "324/363 [=========================>....] - ETA: 0s - loss: 0.3615\n",
      "val/train: 1.17\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.4247\n",
      "Epoch 4/5\n",
      "293/363 [=======================>......] - ETA: 0s - loss: 0.3619\n",
      "val/train: 1.18\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.4261\n",
      "Epoch 5/5\n",
      "300/363 [=======================>......] - ETA: 0s - loss: 0.3603\n",
      "val/train: 1.17\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.4241\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=5,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use GridSearchCV or RandomizedSearchCV wrap the Keras models in objects that minim scikit-learn regressors. Create a function that will build and compile a Keras model given a set of hyperparameters. This will create a model with the given hyperparameters. It will use the stochastic gradient descent optimizer and have just 1 output neuron since this is a univariate regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build keras model\n",
    "def build_model(n_hidden = 1, n_neurons = 30, learning_rate = 1e-3, input_shape = [8]):\n",
    "    # create the model\n",
    "    model = keras.models.Sequential()\n",
    "    # create input layer\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    # for each hidden layer create the same architechure\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    # compile \n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 1e-3)\n",
    "    model.compile(loss = 'mse', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryans\\AppData\\Local\\Temp\\ipykernel_34636\\4087176523.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6533 - val_loss: 0.8857\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7615 - val_loss: 0.7193\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6685 - val_loss: 0.6788\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6256 - val_loss: 0.6360\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5930 - val_loss: 0.6099\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5648 - val_loss: 0.5867\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5410 - val_loss: 0.5692\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5205 - val_loss: 0.5527\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5029 - val_loss: 0.5379\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4881 - val_loss: 0.5248\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4757 - val_loss: 0.5142\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.5062\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4568 - val_loss: 0.5012\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4497 - val_loss: 0.4967\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4436 - val_loss: 0.4900\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4384 - val_loss: 0.4864\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4340 - val_loss: 0.4824\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4302 - val_loss: 0.4798\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4266 - val_loss: 0.4751\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4236 - val_loss: 0.4728\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4716\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4679\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.4663\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4140 - val_loss: 0.4632\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4120 - val_loss: 0.4605\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4612\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4083 - val_loss: 0.4605\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4067 - val_loss: 0.4566\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4048 - val_loss: 0.4569\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4037 - val_loss: 0.4552\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4537\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4007 - val_loss: 0.4507\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3995 - val_loss: 0.4522\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3981 - val_loss: 0.4516\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4492\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4481\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4478\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3935 - val_loss: 0.4461\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3923 - val_loss: 0.4482\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3916 - val_loss: 0.4454\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3906 - val_loss: 0.4436\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.4433\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.4445\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3881 - val_loss: 0.4404\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3871 - val_loss: 0.4414\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4421\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3855 - val_loss: 0.4396\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4383\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.4358\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.4380\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3825 - val_loss: 0.4377\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.4359\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4361\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3804 - val_loss: 0.4361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222a06ac640>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs = 100,\n",
    "              validation_data = (X_valid, y_valid),\n",
    "              callbacks = [keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4541\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.45405617356300354"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000222A0685000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 117ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7668592, 1.7990003, 2.9470072], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7481 - val_loss: 1.1255\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9410 - val_loss: 0.8173\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7792 - val_loss: 0.7322\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7068 - val_loss: 0.6852\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6584 - val_loss: 0.6545\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.6213\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5934 - val_loss: 0.6009\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5669 - val_loss: 0.5779\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5443 - val_loss: 0.5597\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.5463\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5065 - val_loss: 0.5329\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4904 - val_loss: 0.5185\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5076\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.4952\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.4907\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.4816\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4294 - val_loss: 0.4732\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4653\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.4613\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 0.4539\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4516\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4466\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.4410\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.4396\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4401\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.4358\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3754 - val_loss: 0.4331\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.4353\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.4322\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.4292\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3646 - val_loss: 0.4319\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3645 - val_loss: 0.4273\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3620 - val_loss: 0.4251\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3604 - val_loss: 0.4271\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3586 - val_loss: 0.4265\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3580 - val_loss: 0.4248\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3559 - val_loss: 0.4242\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3551 - val_loss: 0.4240\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3537 - val_loss: 0.4219\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3527 - val_loss: 0.4233\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3517 - val_loss: 0.4233\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3512 - val_loss: 0.4207\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3494 - val_loss: 0.4203\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3495 - val_loss: 0.4198\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3485 - val_loss: 0.4192\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3475 - val_loss: 0.4237\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3470 - val_loss: 0.4191\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3467 - val_loss: 0.4210\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3459 - val_loss: 0.4190\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3448 - val_loss: 0.4206\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3446 - val_loss: 0.4182\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3437 - val_loss: 0.4193\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3433 - val_loss: 0.4149\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3429 - val_loss: 0.4206\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3424 - val_loss: 0.4196\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3416 - val_loss: 0.4184\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3413 - val_loss: 0.4186\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3406 - val_loss: 0.4183\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3612\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 7ms/step - loss: 2.7147 - val_loss: 1.0161\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8384 - val_loss: 0.7340\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6987 - val_loss: 0.6610\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6540 - val_loss: 0.6214\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6228 - val_loss: 0.5967\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5952 - val_loss: 0.5751\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5695 - val_loss: 0.5566\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5462 - val_loss: 0.5418\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.5305\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.5187\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5111\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5049\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4616 - val_loss: 0.4993\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 0.4924\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4869\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4825\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4765\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.4733\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.4669\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.4618\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4566\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4532\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.4482\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4443\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4431\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4374\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4341\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.4320\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.4284\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.4264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.4257\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.4203\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3628 - val_loss: 0.4187\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3608 - val_loss: 0.4180\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.4178\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3578 - val_loss: 0.4158\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.4157\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.4130\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.4145\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.4138\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.4101\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.4109\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3484 - val_loss: 0.4099\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.4097\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.4072\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.4077\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3444 - val_loss: 0.4066\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.4070\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3424 - val_loss: 0.4080\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.4069\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.4070\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.4104\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3594\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3055 - val_loss: 1.0514\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8575 - val_loss: 0.7812\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6981 - val_loss: 0.7047\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6392 - val_loss: 0.6631\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6342\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 0.6058\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5421 - val_loss: 0.5832\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5615\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4991 - val_loss: 0.5409\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5269\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.5122\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.5001\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.4885\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.4851\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.4758\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 0.4699\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4654\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.4597\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.4560\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4501\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4444\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.4468\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3898 - val_loss: 0.4424\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.4420\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4418\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.4399\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4380\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.4324\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.4310\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.4307\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.4292\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.4290\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3654 - val_loss: 0.4266\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.4267\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.4276\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.4231\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3590 - val_loss: 0.4224\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3578 - val_loss: 0.4221\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3562 - val_loss: 0.4212\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3550 - val_loss: 0.4213\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3533 - val_loss: 0.4203\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3522 - val_loss: 0.4212\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.4181\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.4206\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.4172\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.4160\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.4144\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.4157\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.4159\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.4135\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.4147\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.4151\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.4150\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.4121\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.4118\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.4121\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.4080\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.4095\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.4085\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.4127\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3344 - val_loss: 0.4072\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.4090\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3324 - val_loss: 0.4090\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.4093\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3305 - val_loss: 0.4081\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3308 - val_loss: 0.4061\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.4111\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.4081\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4057\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.4050\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3270 - val_loss: 0.4072\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3262 - val_loss: 0.4089\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3261 - val_loss: 0.4063\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3250 - val_loss: 0.4060\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4042\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.4066\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3235 - val_loss: 0.4042\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.4070\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3222 - val_loss: 0.4049\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3219 - val_loss: 0.4026\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.4043\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3207 - val_loss: 0.4044\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3201 - val_loss: 0.4011\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3195 - val_loss: 0.4054\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3997\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.4023\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3171 - val_loss: 0.4073\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3182 - val_loss: 0.4020\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3169 - val_loss: 0.4022\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3164 - val_loss: 0.4018\n",
      "121/121 [==============================] - 0s 948us/step - loss: 0.3215\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2241 - val_loss: 1.1816\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.8245\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7434 - val_loss: 0.7050\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 0.6655\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6356 - val_loss: 0.6338\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6152\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5838 - val_loss: 0.5952\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - val_loss: 0.5821\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5458 - val_loss: 0.5687\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5604\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5146 - val_loss: 0.5486\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5022 - val_loss: 0.5406\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4910 - val_loss: 0.5326\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5233\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.5192\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4652 - val_loss: 0.5151\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.5083\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.5065\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.4999\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.4949\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4913\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4884\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.4870\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.4824\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4255 - val_loss: 0.4800\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.4788\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4753\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4188 - val_loss: 0.4751\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.4707\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.4696\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.4688\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4674\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.4643\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.4634\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.4607\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.4614\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.4614\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.4561\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4562\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.4553\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.4563\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4568\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4542\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3966 - val_loss: 0.4534\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.4522\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.4545\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4508\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.4487\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4497\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.4484\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.4487\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.4482\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.4472\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.4455\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.4481\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4455\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.4466\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.4449\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4445\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.4437\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4419\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4442\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.4417\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.4431\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.4399\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4424\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.4426\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4428\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.4443\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.4417\n",
      "121/121 [==============================] - 0s 967us/step - loss: 0.3990\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.1284 - val_loss: 2.1753\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.4871\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3810 - val_loss: 1.2356\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1390 - val_loss: 1.0138\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 0.8207\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7674 - val_loss: 0.6955\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6854 - val_loss: 0.6430\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6501 - val_loss: 0.6153\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.5973\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.5866\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.5760\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5866 - val_loss: 0.5672\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5745 - val_loss: 0.5620\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5633 - val_loss: 0.5577\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.5546\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 0.5541\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.5505\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.5480\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 0.5464\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.5447\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.5431\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.5380\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5374\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4835 - val_loss: 0.5325\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5288\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5246\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4664 - val_loss: 0.5223\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.5192\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.5156\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.5143\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.5082\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.5057\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4399 - val_loss: 0.5008\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4990\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.4955\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 0.4908\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4894\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4240 - val_loss: 0.4850\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.4848\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.4788\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4756\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4743\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.4721\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4685\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4080 - val_loss: 0.4672\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4063 - val_loss: 0.4639\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.4606\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.4599\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4580\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4565\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4551\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.4533\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3960 - val_loss: 0.4519\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3946 - val_loss: 0.4513\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.4494\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3922 - val_loss: 0.4481\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.4472\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4455\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.4453\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3879 - val_loss: 0.4444\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4437\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.4431\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4414\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4407\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4396\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4391\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.4379\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4385\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4366\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4362\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.4365\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4354\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.4341\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.4335\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4332\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4332\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4329\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.4315\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.4307\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.4307\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4298\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4294\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4293\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4302\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4282\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.4290\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.4278\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4276\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.4268\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4264\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.4267\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.4261\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.4251\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.4252\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.4251\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.4236\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4244\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.4229\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.4235\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.4231\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3992\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4101 - val_loss: 1.5658\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3656 - val_loss: 1.1221\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0991 - val_loss: 0.9871\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9800 - val_loss: 0.8975\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8971 - val_loss: 0.8343\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8385 - val_loss: 0.7895\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7945 - val_loss: 0.7532\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7593 - val_loss: 0.7263\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7328 - val_loss: 0.7110\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7097 - val_loss: 0.6903\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6902 - val_loss: 0.6773\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 0.6618\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6591 - val_loss: 0.6538\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6457 - val_loss: 0.6411\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6335 - val_loss: 0.6335\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.6227\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 0.6174\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6090\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5924 - val_loss: 0.6032\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5832 - val_loss: 0.5945\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - val_loss: 0.5889\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5656 - val_loss: 0.5815\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 0.5762\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5493 - val_loss: 0.5702\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5409 - val_loss: 0.5637\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.5574\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.5510\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5175 - val_loss: 0.5445\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 0.5376\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 0.5322\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.5257\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.5198\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.5163\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.5101\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.5040\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.4974\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.4909\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.4858\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4447 - val_loss: 0.4805\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4759\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4711\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4674\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4641\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.4606\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.4578\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4557\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.4541\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4516\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4505\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4486\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4470\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.4465\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 0.4459\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.4441\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4438\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.4417\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.4406\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.4406\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4394\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4383\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4378\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.4372\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.4362\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4360\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4372\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4354\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.4350\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4347\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.4346\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4323\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.4328\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.4324\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3814 - val_loss: 0.4314\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4326\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.4310\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.4328\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4309\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.4310\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.4301\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.4300\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.4289\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.4286\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4283\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.4285\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.4277\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.4269\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4282\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.4279\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.4268\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.4263\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.4256\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.4263\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.4266\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.4264\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.4253\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.4271\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 0.4253\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4270\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.4276\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.4248\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3609\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8416 - val_loss: 1.3226\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0438 - val_loss: 0.7973\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7305 - val_loss: 0.7119\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6710 - val_loss: 0.6800\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6392 - val_loss: 0.6525\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6302\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5898 - val_loss: 0.6132\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5690 - val_loss: 0.5941\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5504 - val_loss: 0.5805\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 0.5659\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 0.5548\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5067 - val_loss: 0.5452\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.5361\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4869 - val_loss: 0.5285\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5212\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.5167\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.5117\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4592 - val_loss: 0.5082\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.5046\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.5003\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4956\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4946\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4378 - val_loss: 0.4906\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.4886\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4865\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4839\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4833\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4807\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 0.4776\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4200 - val_loss: 0.4787\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.4752\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4744\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.4734\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.4713\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.4698\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.4688\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.4679\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4672\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.4670\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.4644\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4636\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4011 - val_loss: 0.4643\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4000 - val_loss: 0.4630\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4610\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4607\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.4597\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4583\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4571\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4571\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.4574\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.4565\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.4559\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4562\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4554\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.4540\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4543\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4520\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.4519\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.4505\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4505\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4498\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4491\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.4491\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.4491\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.4481\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4477\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.4484\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4480\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.4451\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.4471\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4451\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4435\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.4436\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.4438\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.4428\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.4444\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.4419\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4415\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4421\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.4429\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.4396\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.4399\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.4422\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.4397\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.4419\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.4406\n",
      "121/121 [==============================] - 0s 888us/step - loss: 0.3915\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8063 - val_loss: 1.2909\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9617 - val_loss: 0.9083\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7515 - val_loss: 0.7794\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6784 - val_loss: 0.7023\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6333 - val_loss: 0.6523\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 0.6167\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5723 - val_loss: 0.5912\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.5734\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.5600\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.5506\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5047 - val_loss: 0.5406\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4938 - val_loss: 0.5348\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5292\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5200\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.5164\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.5106\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.5081\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4511 - val_loss: 0.5020\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4981\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4935\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4897\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.4854\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.4824\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4801\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.4771\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4728\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4713\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4683\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.4681\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4643\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.4619\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.4603\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4584\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4038 - val_loss: 0.4579\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4550\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 0.4538\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.4517\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4515\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.4481\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4481\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4466\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.4460\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4438\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.4435\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4438\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.4420\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.4412\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4412\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.4407\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4391\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4383\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.4377\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.4373\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4351\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.4359\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3794 - val_loss: 0.4354\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.4358\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4350\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4345\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.4333\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.4337\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.4330\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.4317\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.4318\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4314\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.4306\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.4314\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.4303\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4306\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.4299\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4302\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.4296\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.4284\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.4283\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.4297\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.4284\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.4260\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4273\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.4268\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4268\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.4288\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.4258\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.4258\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.4252\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4252\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.4246\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 0.4259\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.4257\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.4239\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.4252\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.4252\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.4252\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4238\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.4256\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.4230\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.4227\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3605 - val_loss: 0.4223\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.4238\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4232\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3596 - val_loss: 0.4230\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3713\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6281 - val_loss: 1.0608\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.7598\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7620 - val_loss: 0.7088\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7058 - val_loss: 0.6701\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6725 - val_loss: 0.6442\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6441 - val_loss: 0.6255\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 0.6082\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.5876\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5806 - val_loss: 0.5782\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.5650\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.5509\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.5405\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 0.5301\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5212\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4969 - val_loss: 0.5155\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5074\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5022\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.4958\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.4908\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.4865\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.4833\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4799\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4765\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.4719\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.4720\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 0.4679\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 0.4658\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4655\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4629\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4622\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4603\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.4580\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.4594\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.4556\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4559\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 0.4532\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4545\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 0.4531\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4526\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 0.4496\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4502\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4491\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.4495\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4459\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4479\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.4459\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4466\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.4454\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4441\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.4435\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.4451\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.4437\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 0.4433\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.4406\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.4415\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4421\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.4407\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.4395\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4404\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.4387\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4387\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.4375\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4394\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.4363\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4374\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4370\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.4369\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.4381\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4348\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.4374\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.4346\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.4361\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4356\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.4345\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.4341\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4342\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.4328\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.4336\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4314\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4331\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4304\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.4312\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.4309\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.4319\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.4301\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4306\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4311\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4301\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.4306\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.4294\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.4291\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.4303\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.4281\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.4303\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.4290\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.4275\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.4273\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.4290\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.4276\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.4290\n",
      "121/121 [==============================] - 0s 889us/step - loss: 0.3683\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0115 - val_loss: 0.8069\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7331 - val_loss: 0.6436\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6489 - val_loss: 0.6093\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.5783\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - val_loss: 0.5570\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 0.5393\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5176 - val_loss: 0.5268\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4964 - val_loss: 0.5115\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5001\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.4851\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.4914\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4731\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 0.4672\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4212 - val_loss: 0.4633\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.4573\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.4546\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4528\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4481\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.4432\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.4442\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4393\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4404\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.4413\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.4320\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.4340\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.4310\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.4329\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4292\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.4286\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.4302\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3591 - val_loss: 0.4285\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.4260\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3565 - val_loss: 0.4263\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.4253\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.4244\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3516 - val_loss: 0.4256\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3506 - val_loss: 0.4219\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3491 - val_loss: 0.4232\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.4227\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.4233\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3457 - val_loss: 0.4202\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3444 - val_loss: 0.4219\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.4201\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3424 - val_loss: 0.4181\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.4193\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.4188\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.4198\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.4196\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.4163\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3367 - val_loss: 0.4172\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.4177\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.4169\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3343 - val_loss: 0.4166\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.4156\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.4163\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.4149\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3317 - val_loss: 0.4126\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.4166\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.4132\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4153\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.4168\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.4126\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3545\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9676 - val_loss: 0.9114\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7352 - val_loss: 0.6889\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.6231\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 0.5814\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 0.5554\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5352\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5217\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.5111\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4943\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4875\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.4817\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 0.4707\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.4679\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 0.4644\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.4564\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4529\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 0.4509\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4459\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.4448\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3787 - val_loss: 0.4415\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4363\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4358\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.4330\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.4292\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4290\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.4300\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 0.4271\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.4238\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3581 - val_loss: 0.4247\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3565 - val_loss: 0.4267\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3552 - val_loss: 0.4221\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 0.4188\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.4190\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.4188\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.4180\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3483 - val_loss: 0.4155\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3474 - val_loss: 0.4140\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.4130\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3450 - val_loss: 0.4157\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.4136\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.4134\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3419 - val_loss: 0.4134\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.4114\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3400 - val_loss: 0.4120\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.4098\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.4116\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4103\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4086\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.4087\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.4099\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3344 - val_loss: 0.4095\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.4110\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3331 - val_loss: 0.4088\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3469\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1366 - val_loss: 0.8296\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7247 - val_loss: 0.6670\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.6184\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 0.5912\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5635 - val_loss: 0.5661\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.5526\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.5371\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 0.5232\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5155\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.5069\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.4968\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.4895\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4378 - val_loss: 0.4868\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 0.4799\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4235 - val_loss: 0.4743\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.4671\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.4636\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.4622\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4610\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 0.4558\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4518\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4499\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4484\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.4454\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4445\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.4421\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4398\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4399\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.4367\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.4368\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.4358\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4347\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.4322\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.4317\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 0.4309\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.4306\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.4293\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3565 - val_loss: 0.4302\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.4273\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.4269\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.4275\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.4267\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3516 - val_loss: 0.4256\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.4256\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.4240\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3484 - val_loss: 0.4259\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.4247\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.4235\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.4233\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.4233\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.4237\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.4223\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.4220\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.4220\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 0.4200\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 0.4215\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.4200\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.4185\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3383 - val_loss: 0.4206\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3380 - val_loss: 0.4182\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.4203\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3362 - val_loss: 0.4184\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.4197\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.4195\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.4179\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.4194\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.4179\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.4170\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.4183\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.4168\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 0.4152\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3305 - val_loss: 0.4178\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3302 - val_loss: 0.4154\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.4187\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.4129\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.4161\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4167\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.4148\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.4155\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3270 - val_loss: 0.4136\n",
      "121/121 [==============================] - 0s 972us/step - loss: 0.3340\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.5895 - val_loss: 1.0761\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9107 - val_loss: 0.7944\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7350 - val_loss: 0.6927\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6644 - val_loss: 0.6489\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.6165\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 0.5925\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5655 - val_loss: 0.5721\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.5579\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5205 - val_loss: 0.5386\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5025 - val_loss: 0.5258\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5143\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4728 - val_loss: 0.5035\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.4940\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.4854\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4407 - val_loss: 0.4798\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4714\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.4671\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4619\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4584\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.4548\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.4489\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3960 - val_loss: 0.4466\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.4429\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4402\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.4391\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4350\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4351\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4334\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.4300\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.4278\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.4281\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.4256\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.4254\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3603 - val_loss: 0.4236\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.4236\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.4221\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.4237\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 0.4217\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3521 - val_loss: 0.4204\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.4208\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.4204\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3481 - val_loss: 0.4187\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.4158\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.4167\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.4167\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 0.4164\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3426 - val_loss: 0.4167\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3419 - val_loss: 0.4170\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3608\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7907 - val_loss: 0.9408\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7202 - val_loss: 0.7554\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6377 - val_loss: 0.6779\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5918 - val_loss: 0.6226\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - val_loss: 0.5871\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 0.5624\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 0.5341\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5175\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5024\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4917\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.4823\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.4712\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.4648\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.4590\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4530\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4509\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.4451\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.4423\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.4380\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4380\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.4344\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4332\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4298\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.4296\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.4275\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.4260\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.4241\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 0.4228\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.4223\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.4202\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.4232\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.4187\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3543 - val_loss: 0.4190\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.4181\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.4177\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.4206\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.4166\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3484 - val_loss: 0.4167\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.4157\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.4193\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 0.4166\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.4157\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3441 - val_loss: 0.4138\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3431 - val_loss: 0.4133\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.4133\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.4127\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3403 - val_loss: 0.4089\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3403 - val_loss: 0.4112\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.4119\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3386 - val_loss: 0.4088\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3380 - val_loss: 0.4087\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3376 - val_loss: 0.4106\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.4099\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.4090\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.4066\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3343 - val_loss: 0.4096\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.4097\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.4083\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3330 - val_loss: 0.4071\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3326 - val_loss: 0.4086\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3530\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3032 - val_loss: 1.0396\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 0.7764\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7159 - val_loss: 0.7068\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6595 - val_loss: 0.6676\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6233 - val_loss: 0.6346\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5953 - val_loss: 0.6138\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - val_loss: 0.5927\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 0.5778\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5242 - val_loss: 0.5622\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5057 - val_loss: 0.5458\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4884 - val_loss: 0.5315\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.5209\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4609 - val_loss: 0.5144\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4501 - val_loss: 0.5047\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4961\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.4880\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.4808\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.4775\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4738\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4677\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.4703\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4607\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.4626\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.4573\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4535\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.4498\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.4485\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.4463\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.4461\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.4430\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4412\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.4407\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.4375\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.4373\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3633 - val_loss: 0.4359\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.4355\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.4319\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.4346\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.4315\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.4298\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.4293\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.4277\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.4269\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.4263\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.4265\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.4257\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.4238\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.4229\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.4248\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.4241\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.4209\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.4195\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.4216\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4200\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.4224\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.4197\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.4199\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3477\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.7220 - val_loss: 1.3999\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0910 - val_loss: 0.8082\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7310 - val_loss: 0.6902\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6592 - val_loss: 0.6441\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.6148\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5939 - val_loss: 0.5920\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5697 - val_loss: 0.5737\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5492 - val_loss: 0.5583\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 0.5441\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 0.5314\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5019 - val_loss: 0.5221\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.5140\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.5062\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.5002\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.4944\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.4886\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.4851\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4811\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4771\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4754\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.4725\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4684\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4687\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4660\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.4624\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.4613\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.4608\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4586\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4100 - val_loss: 0.4578\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4556\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4559\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.4543\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4543\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4524\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 0.4510\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3993 - val_loss: 0.4505\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.4488\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4485\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4467\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4475\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.4464\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3922 - val_loss: 0.4458\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.4449\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4449\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4443\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4420\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4439\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.4420\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4408\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4414\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4408\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4390\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.4401\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.4381\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.4389\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.4403\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3794 - val_loss: 0.4380\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4374\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.4378\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.4355\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.4354\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4349\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.4351\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4354\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4330\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4334\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4344\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.4325\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.4315\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.4322\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.4315\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.4310\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.4303\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.4295\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.4296\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.4302\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.4296\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.4295\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4292\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.4288\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.4278\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.4280\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 0.4281\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 0.4270\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3629 - val_loss: 0.4277\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.4275\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.4267\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4260\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.4267\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3608 - val_loss: 0.4258\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.4259\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.4249\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.4259\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3594 - val_loss: 0.4239\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.4249\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.4247\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.4249\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.4245\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.4258\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3792\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2798 - val_loss: 1.0999\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8581 - val_loss: 0.8341\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7225 - val_loss: 0.7484\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6701 - val_loss: 0.6966\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6325 - val_loss: 0.6559\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6226\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - val_loss: 0.5942\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5485 - val_loss: 0.5693\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 0.5517\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5360\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4935 - val_loss: 0.5209\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5116\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5009\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.4941\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4860\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.4804\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4767\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.4717\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.4688\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4661\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4628\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.4598\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.4568\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.4547\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 0.4542\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4090 - val_loss: 0.4530\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4511\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.4500\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4507\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4481\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4480\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4471\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.4459\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4453\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4456\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.4447\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4441\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.4433\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.4436\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.4431\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.4426\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.4429\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4422\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4416\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4414\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.4414\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.4403\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4402\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4388\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.4399\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.4389\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4378\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4391\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.4386\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4378\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4372\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.4363\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4387\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4382\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.4362\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.4358\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.4364\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.4356\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4353\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.4342\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3728 - val_loss: 0.4360\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4357\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.4348\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4345\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.4334\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.4345\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.4347\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.4332\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.4327\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.4324\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.4333\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.4324\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.4322\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 0.4332\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.4317\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.4321\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.4322\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.4310\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4311\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.4312\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 0.4311\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.4306\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3634 - val_loss: 0.4295\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.4308\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.4306\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.4303\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.4305\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.4303\n",
      "121/121 [==============================] - 0s 902us/step - loss: 0.3809\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4364 - val_loss: 0.8856\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7868 - val_loss: 0.7157\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 0.6859\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6623 - val_loss: 0.6601\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6347 - val_loss: 0.6372\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6200\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.6020\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5729 - val_loss: 0.5909\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - val_loss: 0.5725\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5416 - val_loss: 0.5627\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 0.5518\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5160 - val_loss: 0.5437\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.5363\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5250\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.5195\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5147\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4708 - val_loss: 0.5082\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5041\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4984\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.4953\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4921\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4863\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.4845\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4807\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4776\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.4745\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.4736\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.4707\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4215 - val_loss: 0.4684\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.4683\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.4633\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.4626\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 0.4622\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.4594\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4583\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 0.4564\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4562\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4049 - val_loss: 0.4568\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.4547\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4527\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.4522\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4000 - val_loss: 0.4500\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4514\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4484\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4493\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4484\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3940 - val_loss: 0.4460\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4462\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.4459\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.4455\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4430\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4448\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.4425\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4423\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.4397\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4421\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.4397\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4418\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.4396\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4391\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.4386\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4388\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4371\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.4372\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3797 - val_loss: 0.4376\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.4361\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.4353\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4351\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4346\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.4348\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.4343\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.4356\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.4341\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.4335\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4331\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4322\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4341\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.4304\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.4326\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.4314\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.4324\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.4291\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.4323\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.4296\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.4289\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.4302\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.4301\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.4294\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4284\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 0.4279\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.4278\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.4273\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 0.4285\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4260\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3647 - val_loss: 0.4280\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.4266\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.4291\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3647 - val_loss: 0.4263\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.4251\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3634 - val_loss: 0.4253\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3641\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8660 - val_loss: 1.3338\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0568 - val_loss: 0.8480\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7953 - val_loss: 0.7344\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7142 - val_loss: 0.6828\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6752 - val_loss: 0.6550\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6449 - val_loss: 0.6293\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6208 - val_loss: 0.6115\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.5954\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5826 - val_loss: 0.5808\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5672 - val_loss: 0.5691\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5523 - val_loss: 0.5576\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5498\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 0.5403\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.5311\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5057 - val_loss: 0.5236\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 0.5178\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5115\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.5063\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.5016\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.4978\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.4935\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.4906\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.4877\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.4840\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.4827\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 0.4794\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4791\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4761\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4746\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 0.4725\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.4708\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.4698\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.4681\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4659\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4655\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4647\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4632\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4215 - val_loss: 0.4620\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.4604\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4595\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4594\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.4585\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.4583\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4570\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4557\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.4547\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.4543\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.4536\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.4533\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.4515\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4077 - val_loss: 0.4519\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.4505\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4501\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.4496\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.4488\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4039 - val_loss: 0.4485\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.4476\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.4478\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4468\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.4467\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4459\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.4461\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4457\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.4456\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4441\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4441\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.4448\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4445\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4441\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4431\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4420\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4427\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4413\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.4408\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 0.4416\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3904 - val_loss: 0.4404\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3898 - val_loss: 0.4401\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.4405\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4402\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4408\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.4398\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.4398\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 0.4385\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.4388\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4383\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4373\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4379\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.4376\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.4371\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.4372\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4371\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.4362\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3817 - val_loss: 0.4365\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4359\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.4361\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4367\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.4365\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4369\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.4358\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4351\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3939\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.6070 - val_loss: 1.2441\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0698 - val_loss: 0.9489\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8879 - val_loss: 0.8469\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8061 - val_loss: 0.7864\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7526 - val_loss: 0.7465\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7119 - val_loss: 0.7154\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6782 - val_loss: 0.6897\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6490 - val_loss: 0.6678\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6238 - val_loss: 0.6496\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6335\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5818 - val_loss: 0.6182\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5642 - val_loss: 0.6042\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5483 - val_loss: 0.5918\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5800\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.5713\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5107 - val_loss: 0.5613\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.5526\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5439\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5376\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5301\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5242\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4631 - val_loss: 0.5181\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.5136\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.5092\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4479 - val_loss: 0.5041\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4991\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.4965\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4358 - val_loss: 0.4912\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 0.4887\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.4862\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4829\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4235 - val_loss: 0.4814\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4776\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 0.4742\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.4721\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.4703\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.4669\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4650\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 0.4646\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4073 - val_loss: 0.4624\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4057 - val_loss: 0.4615\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4044 - val_loss: 0.4587\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.4566\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.4558\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4543\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4512\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.4511\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4503\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4491\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4473\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3938 - val_loss: 0.4475\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3928 - val_loss: 0.4467\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4460\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.4434\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3903 - val_loss: 0.4438\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.4420\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4426\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4431\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3872 - val_loss: 0.4403\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 0.4400\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4404\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.4394\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3844 - val_loss: 0.4397\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.4381\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4372\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4376\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 0.4374\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4361\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3809 - val_loss: 0.4353\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4356\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.4354\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4363\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.4352\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4352\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3778 - val_loss: 0.4346\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.4337\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.4341\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3766 - val_loss: 0.4337\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3761 - val_loss: 0.4329\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.4328\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4334\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.4323\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4333\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4322\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4323\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3732 - val_loss: 0.4331\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.4317\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4301\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.4301\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.4304\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.4326\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4319\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.4313\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3832\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4114 - val_loss: 1.0073\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8467 - val_loss: 0.7783\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7136 - val_loss: 0.7265\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6725 - val_loss: 0.6982\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6426 - val_loss: 0.6744\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.6526\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5954 - val_loss: 0.6360\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5760 - val_loss: 0.6193\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5592 - val_loss: 0.6040\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5443 - val_loss: 0.5921\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5308 - val_loss: 0.5808\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.5697\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5074 - val_loss: 0.5593\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4973 - val_loss: 0.5488\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4886 - val_loss: 0.5437\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.5353\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5300\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.5234\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.5184\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.5136\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4536 - val_loss: 0.5093\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4498 - val_loss: 0.5058\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 0.5042\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.5018\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4406 - val_loss: 0.4965\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4378 - val_loss: 0.4951\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4357 - val_loss: 0.4921\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4333 - val_loss: 0.4913\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.4891\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4296 - val_loss: 0.4860\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4277 - val_loss: 0.4849\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.4815\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 0.4807\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4233 - val_loss: 0.4796\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.4787\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4209 - val_loss: 0.4762\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.4760\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.4750\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4738\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4732\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4715\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.4717\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.4691\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.4680\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4681\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4676\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.4654\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4084 - val_loss: 0.4657\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4647\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4069 - val_loss: 0.4641\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4620\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.4603\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4044 - val_loss: 0.4599\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4597\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4589\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 0.4579\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.4584\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4006 - val_loss: 0.4571\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4558\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.4557\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.4546\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4538\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4540\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3965 - val_loss: 0.4532\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.4525\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4511\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4517\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.4512\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3938 - val_loss: 0.4496\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3929 - val_loss: 0.4492\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3922 - val_loss: 0.4482\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.4480\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3912 - val_loss: 0.4481\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.4463\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.4462\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4458\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3891 - val_loss: 0.4457\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3885 - val_loss: 0.4450\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4445\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3877 - val_loss: 0.4443\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4442\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.4448\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3864 - val_loss: 0.4443\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3861 - val_loss: 0.4436\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.4423\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3849 - val_loss: 0.4436\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4417\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4419\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4415\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4407\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.4400\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4398\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4408\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 0.4410\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3814 - val_loss: 0.4400\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3813 - val_loss: 0.4389\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.4389\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3803 - val_loss: 0.4392\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3801 - val_loss: 0.4389\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.4396\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3763\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3872 - val_loss: 0.9406\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8093 - val_loss: 0.7024\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6965 - val_loss: 0.6552\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6526 - val_loss: 0.6246\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6135 - val_loss: 0.5984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5788 - val_loss: 0.5679\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5505 - val_loss: 0.5457\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5272\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4977 - val_loss: 0.5104\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4760 - val_loss: 0.4934\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4877\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4688\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.4646\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.4582\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4489\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.4484\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.4449\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.4399\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4382\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.4336\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4316\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4316\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.4279\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.4295\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4300\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.4273\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.4253\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.4237\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.4234\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3564 - val_loss: 0.4224\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.4210\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3533 - val_loss: 0.4203\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.4220\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.4192\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.4212\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3485 - val_loss: 0.4181\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.4191\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.4231\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.4199\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.4169\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.4189\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.4180\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.4166\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3409 - val_loss: 0.4199\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3400 - val_loss: 0.4162\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.4178\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.4169\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3376 - val_loss: 0.4174\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3372 - val_loss: 0.4144\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.4203\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.4148\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.4143\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.4148\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.4156\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.4158\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.4160\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 0.4148\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3564\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3126 - val_loss: 1.1917\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8613 - val_loss: 0.8134\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6926 - val_loss: 0.7155\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6358 - val_loss: 0.6531\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5957 - val_loss: 0.6135\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 0.5862\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 0.5548\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 0.5347\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5234\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.5025\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4926\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4822\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.4777\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4677\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.4644\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.4548\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.4531\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4522\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3904 - val_loss: 0.4474\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4444\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.4393\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3794 - val_loss: 0.4368\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.4376\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4346\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4320\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.4304\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.4269\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.4293\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.4252\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.4237\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.4234\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.4220\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.4242\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3538 - val_loss: 0.4205\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.4230\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.4195\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.4220\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.4191\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.4175\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.4201\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.4161\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.4197\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3426 - val_loss: 0.4156\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.4176\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 0.4151\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3397 - val_loss: 0.4185\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.4162\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.4212\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.4141\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.4128\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.4121\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.4136\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.4124\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3331 - val_loss: 0.4125\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.4124\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.4122\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3487\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.7153 - val_loss: 1.0684\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8402 - val_loss: 0.6610\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.5882\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5710 - val_loss: 0.5610\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.5431\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 0.5228\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5059\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.4927\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.4823\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.4720\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4636\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.4568\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.4558\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.4463\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4415\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.4392\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.4390\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4328\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.4311\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4280\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.4285\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.4242\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.4231\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4217\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.4209\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.4201\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.4197\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.4168\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.4192\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.4182\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.4150\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.4153\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.4147\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3552 - val_loss: 0.4136\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 0.4160\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.4180\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 0.4123\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 0.4135\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.4118\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.4110\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.4089\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.4099\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.4094\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3457 - val_loss: 0.4090\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.4096\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.4073\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.4087\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.4095\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.4069\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3407 - val_loss: 0.4080\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3407 - val_loss: 0.4060\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.4080\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.4058\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3380 - val_loss: 0.4083\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.4049\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.4071\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.4046\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3360 - val_loss: 0.4054\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.4067\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.4058\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.4038\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3332 - val_loss: 0.4041\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.4045\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.4055\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3313 - val_loss: 0.4035\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3304 - val_loss: 0.4023\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.4054\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.4032\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3289 - val_loss: 0.4049\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.4020\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4030\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.4015\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.4049\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.4020\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3265 - val_loss: 0.4038\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3265 - val_loss: 0.4006\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3253 - val_loss: 0.4023\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3244 - val_loss: 0.4002\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3242 - val_loss: 0.4006\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.4005\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3226 - val_loss: 0.4031\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3226 - val_loss: 0.3991\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3221 - val_loss: 0.4014\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3210 - val_loss: 0.4027\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3216 - val_loss: 0.3994\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.4001\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3207 - val_loss: 0.4009\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3309\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7469 - val_loss: 1.3491\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0540 - val_loss: 0.8411\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7613 - val_loss: 0.6875\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6742 - val_loss: 0.6355\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6316 - val_loss: 0.6060\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 0.5834\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5752 - val_loss: 0.5681\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5534 - val_loss: 0.5495\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5340 - val_loss: 0.5377\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5168 - val_loss: 0.5252\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5012 - val_loss: 0.5154\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4873 - val_loss: 0.5070\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.4959\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.4900\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.4860\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4456 - val_loss: 0.4789\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4730\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4314 - val_loss: 0.4685\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4254 - val_loss: 0.4653\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.4612\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.4572\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4561\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.4524\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4498\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.4465\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.4474\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4472\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.4413\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 0.4416\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.4393\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3843 - val_loss: 0.4368\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.4371\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.4342\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4334\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.4343\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.4302\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.4279\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.4282\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3698 - val_loss: 0.4290\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4273\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3672 - val_loss: 0.4301\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.4246\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3648 - val_loss: 0.4252\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3633 - val_loss: 0.4247\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4217\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.4247\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.4214\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.4212\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.4186\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.4208\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.4172\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4171\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3531 - val_loss: 0.4217\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4189\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.4179\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3507 - val_loss: 0.4171\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3494 - val_loss: 0.4167\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.4171\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.4169\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.4151\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.4162\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3457 - val_loss: 0.4158\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.4154\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4151\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.4141\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.4166\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.4146\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.4134\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3408 - val_loss: 0.4135\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3403 - val_loss: 0.4130\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.4133\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3388 - val_loss: 0.4129\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.4120\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.4121\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3375 - val_loss: 0.4123\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.4121\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3362 - val_loss: 0.4118\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3357 - val_loss: 0.4119\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.4124\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3348 - val_loss: 0.4108\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.4098\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.4111\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3333 - val_loss: 0.4102\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.4106\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.4117\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.4120\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3630\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1814 - val_loss: 1.2170\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9762 - val_loss: 0.8722\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7981 - val_loss: 0.7587\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7236 - val_loss: 0.6873\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6759 - val_loss: 0.6502\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6384 - val_loss: 0.6211\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.5980\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5800 - val_loss: 0.5797\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5567 - val_loss: 0.5636\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 0.5547\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5168 - val_loss: 0.5394\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4998 - val_loss: 0.5314\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4846 - val_loss: 0.5191\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4707 - val_loss: 0.5140\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.4997\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4476 - val_loss: 0.4907\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4385 - val_loss: 0.4842\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4807\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.4739\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4680\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4130 - val_loss: 0.4634\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 0.4617\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4590\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4561\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4537\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4483\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4465\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4461\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.4423\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4413\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.4394\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 0.4387\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3845 - val_loss: 0.4371\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4346\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.4344\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.4327\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.4319\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.4332\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.4312\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4307\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4294\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3747 - val_loss: 0.4286\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3739 - val_loss: 0.4274\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.4259\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3717 - val_loss: 0.4249\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4252\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3702 - val_loss: 0.4235\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.4235\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.4238\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.4232\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.4226\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.4218\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3654 - val_loss: 0.4219\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.4204\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.4208\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.4207\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.4186\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 0.4194\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3612 - val_loss: 0.4183\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.4188\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.4179\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.4188\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.4186\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4190\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.4172\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4172\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.4159\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4164\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3550 - val_loss: 0.4158\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3544 - val_loss: 0.4175\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3538 - val_loss: 0.4154\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.4164\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.4153\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3522 - val_loss: 0.4156\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3517 - val_loss: 0.4155\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.4157\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.4138\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3499 - val_loss: 0.4165\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.4141\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.4149\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.4137\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.4152\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.4144\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 0.4130\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.4145\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.4149\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.4139\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.4124\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.4128\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.4128\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3435 - val_loss: 0.4121\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.4132\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.4125\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.4120\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.4129\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.4118\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.4114\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.4111\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.4095\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4117\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3637\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.1426 - val_loss: 1.1784\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.7504\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7016 - val_loss: 0.6610\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.6260\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6056\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 0.5892\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - val_loss: 0.5743\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5449 - val_loss: 0.5614\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5284 - val_loss: 0.5490\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5133 - val_loss: 0.5361\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4993 - val_loss: 0.5259\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4864 - val_loss: 0.5124\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5049\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.4951\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4562 - val_loss: 0.4877\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4808\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4746\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4701\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 0.4648\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4251 - val_loss: 0.4606\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.4562\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.4534\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4128 - val_loss: 0.4511\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4093 - val_loss: 0.4468\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4475\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.4447\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4004 - val_loss: 0.4405\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.4404\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4401\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4377\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3915 - val_loss: 0.4359\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3896 - val_loss: 0.4343\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3879 - val_loss: 0.4330\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3862 - val_loss: 0.4320\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 0.4308\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.4328\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4309\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.4303\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.4283\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.4281\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4286\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4299\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.4265\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3732 - val_loss: 0.4296\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4261\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.4267\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.4241\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.4247\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.4263\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4239\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3669 - val_loss: 0.4248\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.4240\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3654 - val_loss: 0.4233\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3646 - val_loss: 0.4229\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3639 - val_loss: 0.4235\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4231\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.4221\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.4225\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4217\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.4219\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3594 - val_loss: 0.4217\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.4212\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.4205\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4221\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4212\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 0.4196\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.4191\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.4207\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.4194\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3539 - val_loss: 0.4177\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.4172\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3529 - val_loss: 0.4185\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3524 - val_loss: 0.4192\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.4196\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.4193\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3507 - val_loss: 0.4169\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.4178\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.4175\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.4156\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.4167\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.4173\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.4162\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 0.4164\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.4162\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3466\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4633 - val_loss: 1.2885\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0688 - val_loss: 0.8807\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8281 - val_loss: 0.7548\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7360 - val_loss: 0.6954\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6853 - val_loss: 0.6584\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6491 - val_loss: 0.6310\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.6083\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.5903\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5798 - val_loss: 0.5749\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5633 - val_loss: 0.5615\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.5508\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5352 - val_loss: 0.5375\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5232 - val_loss: 0.5286\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5124 - val_loss: 0.5195\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5026 - val_loss: 0.5118\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5068\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.4992\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.4935\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4714 - val_loss: 0.4891\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.4839\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.4792\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.4762\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4494 - val_loss: 0.4725\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4449 - val_loss: 0.4699\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4668\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4640\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.4625\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4602\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.4583\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4250 - val_loss: 0.4567\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 0.4554\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4203 - val_loss: 0.4544\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.4533\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4519\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4505\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.4499\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4485\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4482\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 0.4479\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4464\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 0.4464\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4043 - val_loss: 0.4451\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.4459\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.4449\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.4437\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4000 - val_loss: 0.4437\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 0.4419\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4426\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4409\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3964 - val_loss: 0.4422\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3958 - val_loss: 0.4410\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3949 - val_loss: 0.4396\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3943 - val_loss: 0.4399\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.4390\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4391\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.4396\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.4387\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.4382\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.4387\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4370\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3889 - val_loss: 0.4373\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3882 - val_loss: 0.4369\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3877 - val_loss: 0.4368\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.4365\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.4363\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.4353\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4369\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.4368\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4346\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.4339\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.4339\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.4342\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.4337\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4339\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3817 - val_loss: 0.4324\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.4331\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4332\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4318\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.4321\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.4325\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.4315\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.4326\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4312\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3776 - val_loss: 0.4314\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.4309\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3768 - val_loss: 0.4306\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3765 - val_loss: 0.4300\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.4304\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.4301\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4302\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4297\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.4289\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4286\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.4294\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4302\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3731 - val_loss: 0.4282\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3727 - val_loss: 0.4287\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.4269\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4293\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.4277\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3875\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1786 - val_loss: 1.4697\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0867 - val_loss: 0.8684\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7541 - val_loss: 0.7011\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6609 - val_loss: 0.6479\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6261 - val_loss: 0.6230\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6049 - val_loss: 0.6077\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5878 - val_loss: 0.5935\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5723 - val_loss: 0.5818\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5580 - val_loss: 0.5717\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.5636\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 0.5549\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5467\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5116 - val_loss: 0.5388\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.5324\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5261\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.5203\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.5142\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4726 - val_loss: 0.5096\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4668 - val_loss: 0.5048\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4616 - val_loss: 0.5006\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4566 - val_loss: 0.4965\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.4916\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.4896\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.4865\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.4827\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4794\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4787\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.4764\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4304 - val_loss: 0.4747\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4283 - val_loss: 0.4705\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4262 - val_loss: 0.4695\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4244 - val_loss: 0.4674\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.4663\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.4640\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4194 - val_loss: 0.4629\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4179 - val_loss: 0.4614\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4165 - val_loss: 0.4618\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.4602\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.4588\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.4585\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4577\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4569\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4093 - val_loss: 0.4576\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4554\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.4545\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 0.4544\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4547\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4548\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4526\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.4517\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4026 - val_loss: 0.4519\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4017 - val_loss: 0.4521\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4517\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4499\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.4506\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.4500\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.4505\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.4497\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4510\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3965 - val_loss: 0.4477\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.4490\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4491\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4473\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4479\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3941 - val_loss: 0.4486\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3935 - val_loss: 0.4475\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4468\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3926 - val_loss: 0.4475\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.4476\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.4472\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.4469\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3905 - val_loss: 0.4479\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4091\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.0585 - val_loss: 1.2626\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9282 - val_loss: 0.7435\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6816 - val_loss: 0.6558\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6229 - val_loss: 0.6203\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5888 - val_loss: 0.5915\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5616 - val_loss: 0.5680\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5401 - val_loss: 0.5516\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5217 - val_loss: 0.5368\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5066 - val_loss: 0.5253\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4938 - val_loss: 0.5159\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4831 - val_loss: 0.5076\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4738 - val_loss: 0.5000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4659 - val_loss: 0.4941\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4592 - val_loss: 0.4894\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4534 - val_loss: 0.4847\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4486 - val_loss: 0.4810\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4443 - val_loss: 0.4776\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4405 - val_loss: 0.4735\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4711\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4349 - val_loss: 0.4682\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4325 - val_loss: 0.4673\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.4642\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4284 - val_loss: 0.4638\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4267 - val_loss: 0.4631\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4252 - val_loss: 0.4595\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4609\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4224 - val_loss: 0.4588\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4212 - val_loss: 0.4566\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4563\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4188 - val_loss: 0.4554\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4178 - val_loss: 0.4535\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.4534\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4536\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4520\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4523\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4510\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4505\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4117 - val_loss: 0.4496\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4479\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4484\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4468\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4478\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4078 - val_loss: 0.4478\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4477\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4468\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4470\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4446\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4448\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4450\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4428\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4421\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4415\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4420\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4416\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4405\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4403\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 0.4403\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.4397\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4396\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4386\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3972 - val_loss: 0.4371\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 0.4389\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4380\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.4378\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4373\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4352\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3942 - val_loss: 0.4355\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4356\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.4357\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.4364\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.4353\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3886\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.7643 - val_loss: 0.8335\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7187 - val_loss: 0.6563\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6193 - val_loss: 0.6083\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5669 - val_loss: 0.5710\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5263 - val_loss: 0.5430\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4941 - val_loss: 0.5251\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4681 - val_loss: 0.5016\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4881\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4304 - val_loss: 0.4810\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4169 - val_loss: 0.4686\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4613\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3967 - val_loss: 0.4557\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.4497\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3832 - val_loss: 0.4465\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4418\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3739 - val_loss: 0.4415\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.4355\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.4331\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4312\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3612 - val_loss: 0.4307\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4270\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4251\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.4253\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.4228\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.4239\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4185\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4180\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4166\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3446 - val_loss: 0.4150\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.4160\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.4155\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3411 - val_loss: 0.4137\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3403 - val_loss: 0.4120\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.4122\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3378 - val_loss: 0.4119\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.4114\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3355 - val_loss: 0.4105\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3349 - val_loss: 0.4084\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3335 - val_loss: 0.4100\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.4075\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.4072\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3309 - val_loss: 0.4078\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3304 - val_loss: 0.4055\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.4072\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.4098\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3279 - val_loss: 0.4063\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3266 - val_loss: 0.4063\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3266 - val_loss: 0.4063\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000222A03DC190&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002228A4A6050&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [1, 2, 3, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000222A03DC190&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002228A4A6050&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [1, 2, 3, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: KerasRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000002228A8B30A0&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KerasRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000002228A8B30A0&gt;</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000222A03DC190>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002228A4A6050>,\n",
       "                                        'n_hidden': [1, 2, 3, 3],\n",
       "                                        'n_neurons': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    'n_hidden': [1, 2, 3, 3],\n",
    "    'n_neurons': np.arange(0, 100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter = 10, cv = 3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs = 100, \n",
    "                  validation_data = (X_valid, y_valid),\n",
    "                  callbacks = keras.callbacks.EarlyStopping(patience = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.00698840892273627, 'n_hidden': 3, 'n_neurons': 74}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Scikit-Learn wants scores instead of loss value it is the opposite of the MSE since higher should be better. This means the more negative the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3451199233531952"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42744770646095276"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7976567],\n",
       "       [1.5856781],\n",
       "       [3.336946 ]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
