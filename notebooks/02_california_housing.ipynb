{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### California Housing Regression Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bunch object which is a special sklearn object\n",
    "It behaves like a dictionary (housing['data'], housing['target']).\n",
    "\n",
    "Contains multiple attributes:\n",
    "\n",
    "housing.data → The actual housing feature data (NumPy array).\n",
    "\n",
    "housing.target → The target values (median house price).\n",
    "\n",
    "housing.feature_names → The names of each feature.\n",
    "\n",
    "housing.DESCR → Description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split of housing data which is a numpy array\n",
    "X_train_full, X_test, y_train_full, y_test= train_test_split(housing.data, housing.target, test_size=0.25, random_state= 42)\n",
    "\n",
    "# make a validation set for the compiling\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6934 - val_loss: 0.5099\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4627\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4253 - val_loss: 0.5128\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.6209\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.4936\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.4637\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4414\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.4322\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4377\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.4274\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.4268\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4319\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4367\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4263\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.4228\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4226\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.4268\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.4264\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.4182\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.4293\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.4153\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.4173\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.4174\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.4406\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4252\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.4168\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.4167\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.4237\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4131\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.4123\n"
     ]
    }
   ],
   "source": [
    "# fit the model save as history\n",
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "# make fake new houses\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6190179],\n",
       "       [1.7084866],\n",
       "       [3.0323572]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare them\n",
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonsequential Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example is when the input layer connects all or part of the inputs directly to the output layer so that the neural network can learn both deep patterns and simple patterns. This is because the deep patterns are learned going the sequential route and the simple patterns are caught by jumping to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonsequential build\n",
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "# pass the input to this hidden layer with 30 neurons\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "# pass the output from the first hidden layer to this hidden layer\n",
    "hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n",
    "# concatenate the input and the ouput of the second hidden layer\n",
    "concat = keras.layers.Concatenate()([input_, hidden_2])\n",
    "# pass in the result of the concatenation to this output layer\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 30)           270         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           930         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 38)           0           ['input_2[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            39          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile this model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1412 - val_loss: 1.5670\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9188 - val_loss: 0.7416\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6418 - val_loss: 0.6481\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6025 - val_loss: 0.6264\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5751 - val_loss: 0.6091\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5519 - val_loss: 0.5919\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5328 - val_loss: 0.5672\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5160 - val_loss: 0.5500\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5007 - val_loss: 0.5406\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4882 - val_loss: 0.5233\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4764 - val_loss: 0.5172\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4669 - val_loss: 0.5073\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4583 - val_loss: 0.5021\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4504 - val_loss: 0.4939\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4437 - val_loss: 0.4898\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4375 - val_loss: 0.4841\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4792\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4760\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4226 - val_loss: 0.4741\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4184 - val_loss: 0.4687\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 961us/step - loss: 0.4903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4903166592121124"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mse on testing\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 128ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.56534386],\n",
       "       [1.7663002 ],\n",
       "       [2.8565946 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting the Wide and Deep Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can send some data only through the wide path for the simple relationships and then send a different subset through the deep path to learn the more complex relationships. Often times we may want the features to overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting the deep and wide paths\n",
    "\n",
    "# create input A for the wide path (wont go through all layers)\n",
    "# takes shape = [5] for 5 features\n",
    "input_A = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "# create input B which goes the deep path and has 6 features\n",
    "input_B = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n",
    "# concatenate layer takes the wide path and output from deep path\n",
    "concat = keras.layers.Concatenate()([input_A, hidden_2])\n",
    "# single output for house price\n",
    "output = keras.layers.Dense(1, name = 'ouput')(concat)\n",
    "\n",
    "# make the model\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compile this model it is the same process but when we fit it we have to fit it to the two subsets. This means we first need to make the two subsets. We will also need to make the \"new\" data which is just the first three rows of the data that have already been reshaped.\n",
    "\n",
    "Input A uses the first 5 features and Input B uses the last 6 so there is some overlap here. Both subsets will use features 2, 3, 4 and 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X train and valid sets for each subset\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "\n",
    "# create validation for each \n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "\n",
    "# create the correct test data\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "\n",
    "\n",
    "# this is for making the predictions later\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = keras.optimizers.SGD(learning_rate = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show both ways to call model.fit with multiple inputs. We can pass them as a dictionary or a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1374 - val_loss: 0.8561\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8008 - val_loss: 0.7111\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7005 - val_loss: 0.6522\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6532 - val_loss: 0.6202\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6207 - val_loss: 0.5972\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5954 - val_loss: 0.5772\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.5603\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5550 - val_loss: 0.5471\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5386 - val_loss: 0.5345\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5238 - val_loss: 0.5230\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5106 - val_loss: 0.5158\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4990 - val_loss: 0.5091\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4889 - val_loss: 0.5024\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4798 - val_loss: 0.4945\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4722 - val_loss: 0.4941\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4895\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4859\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4538 - val_loss: 0.4839\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4490 - val_loss: 0.4817\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4448 - val_loss: 0.4793\n"
     ]
    }
   ],
   "source": [
    "history = model.fit({'wide_input': X_train_A, 'deep_input': X_train_B}, y_train, epochs = 20,\n",
    "                     validation_data = ({'wide_input': X_valid_A, 'deep_input': X_valid_B}, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0847 - val_loss: 0.8919\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7489 - val_loss: 0.6893\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6556 - val_loss: 0.6444\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6142 - val_loss: 0.6057\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5821 - val_loss: 0.5811\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5545 - val_loss: 0.5594\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5312 - val_loss: 0.5431\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5289\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4958 - val_loss: 0.5196\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4831 - val_loss: 0.5101\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4731 - val_loss: 0.4997\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4646 - val_loss: 0.4947\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4579 - val_loss: 0.4884\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4522 - val_loss: 0.4832\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4477 - val_loss: 0.4786\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4783\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4402 - val_loss: 0.4757\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4373 - val_loss: 0.4741\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4344 - val_loss: 0.4716\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4703\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4298 - val_loss: 0.4679\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4275 - val_loss: 0.4653\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4257 - val_loss: 0.4655\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.4636\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4223 - val_loss: 0.4626\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4639\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4191 - val_loss: 0.4647\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4180 - val_loss: 0.4598\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 0.4585\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4152 - val_loss: 0.4599\n"
     ]
    }
   ],
   "source": [
    "# create the history \n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs = 30,\n",
    "                    validation_data = ((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4818\n"
     ]
    }
   ],
   "source": [
    "# testing data\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is often the case, the testing data performs slightly worse than the validation data but not by much so it is not overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48181331157684326"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6114548],\n",
       "       [1.9770505],\n",
       "       [2.761712 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we may have to take multiple inputs. If we are trying to locate and classify the main object in a picture it is a regression task to find the coordinates of the objects center along with the width and height, and a classification task.\n",
    "\n",
    "We can also have a single neural network responsible for many different individual tasks such as a multiclass classification network where output 1 determines the center of an image and output 2 determines the facial expression.\n",
    "\n",
    "We can also add an auxilary output as a regularization technique. This will avoid the concatenation which makes the model learn from the neural network without being put in a layer wiht the inputs at the end (pg. 312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding auxilary output\n",
    "input_A = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "input_B = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "\n",
    "# input_B goes deep\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n",
    "\n",
    "# input A jumps here\n",
    "concat = keras.layers.concatenate([input_A, hidden_2])\n",
    "# main output is deep and wide inputs\n",
    "output = keras.layers.Dense(1, name = 'main_output')(concat)\n",
    "\n",
    "# splits away from concat layer after the hidden layer 2\n",
    "aux_output = keras.layers.Dense(1, name = 'aux_output')(hidden_2)\n",
    "\n",
    "# create model with two inputs and two outputs\n",
    "model = keras.models.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output is added up with their own loss function at the end of training. Since the auxilary output is just used for regularization we want to set wieghts to these different losses which is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.SGD(learning_rate=1e-3), loss = ['mse', 'mse'], loss_weights=[0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I used both the dictionary naming convention when fitting the model and also the list convention. Your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6664 - main_output_loss: 2.4374 - aux_output_loss: 4.7277 - val_loss: 1.2146 - val_main_output_loss: 0.9676 - val_aux_output_loss: 3.4375\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0694 - main_output_loss: 0.8727 - aux_output_loss: 2.8395 - val_loss: 0.8960 - val_main_output_loss: 0.7520 - val_aux_output_loss: 2.1912\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8668 - main_output_loss: 0.7435 - aux_output_loss: 1.9759 - val_loss: 0.7884 - val_main_output_loss: 0.6887 - val_aux_output_loss: 1.6853\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7789 - main_output_loss: 0.6857 - aux_output_loss: 1.6170 - val_loss: 0.7328 - val_main_output_loss: 0.6492 - val_aux_output_loss: 1.4855\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7294 - main_output_loss: 0.6481 - aux_output_loss: 1.4613 - val_loss: 0.6964 - val_main_output_loss: 0.6180 - val_aux_output_loss: 1.4014\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6965 - main_output_loss: 0.6200 - aux_output_loss: 1.3853 - val_loss: 0.6748 - val_main_output_loss: 0.5993 - val_aux_output_loss: 1.3541\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6718 - main_output_loss: 0.5978 - aux_output_loss: 1.3376 - val_loss: 0.6571 - val_main_output_loss: 0.5831 - val_aux_output_loss: 1.3239\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6516 - main_output_loss: 0.5793 - aux_output_loss: 1.3032 - val_loss: 0.6474 - val_main_output_loss: 0.5750 - val_aux_output_loss: 1.2990\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6350 - main_output_loss: 0.5640 - aux_output_loss: 1.2740 - val_loss: 0.6334 - val_main_output_loss: 0.5619 - val_aux_output_loss: 1.2770\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6203 - main_output_loss: 0.5504 - aux_output_loss: 1.2492 - val_loss: 0.6234 - val_main_output_loss: 0.5530 - val_aux_output_loss: 1.2564\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6071 - main_output_loss: 0.5385 - aux_output_loss: 1.2252 - val_loss: 0.6148 - val_main_output_loss: 0.5456 - val_aux_output_loss: 1.2368\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5959 - main_output_loss: 0.5283 - aux_output_loss: 1.2038 - val_loss: 0.6074 - val_main_output_loss: 0.5396 - val_aux_output_loss: 1.2174\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5852 - main_output_loss: 0.5189 - aux_output_loss: 1.1820 - val_loss: 0.6004 - val_main_output_loss: 0.5339 - val_aux_output_loss: 1.1989\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5758 - main_output_loss: 0.5106 - aux_output_loss: 1.1622 - val_loss: 0.5965 - val_main_output_loss: 0.5316 - val_aux_output_loss: 1.1810\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5669 - main_output_loss: 0.5029 - aux_output_loss: 1.1422 - val_loss: 0.5892 - val_main_output_loss: 0.5254 - val_aux_output_loss: 1.1633\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5588 - main_output_loss: 0.4961 - aux_output_loss: 1.1232 - val_loss: 0.5845 - val_main_output_loss: 0.5221 - val_aux_output_loss: 1.1454\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5516 - main_output_loss: 0.4902 - aux_output_loss: 1.1043 - val_loss: 0.5771 - val_main_output_loss: 0.5159 - val_aux_output_loss: 1.1280\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5443 - main_output_loss: 0.4841 - aux_output_loss: 1.0862 - val_loss: 0.5762 - val_main_output_loss: 0.5167 - val_aux_output_loss: 1.1110\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5383 - main_output_loss: 0.4795 - aux_output_loss: 1.0682 - val_loss: 0.5696 - val_main_output_loss: 0.5113 - val_aux_output_loss: 1.0942\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5321 - main_output_loss: 0.4744 - aux_output_loss: 1.0511 - val_loss: 0.5652 - val_main_output_loss: 0.5084 - val_aux_output_loss: 1.0768\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], \n",
    "    [y_train, y_train],\n",
    "    epochs=20, \n",
    "    validation_data=(\n",
    "    [X_valid_A, X_valid_B], \n",
    "    [y_valid, y_valid]\n",
    ")\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.5265 - main_output_loss: 0.4702 - aux_output_loss: 1.0337 - val_loss: 0.5601 - val_main_output_loss: 0.5045 - val_aux_output_loss: 1.0604\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5210 - main_output_loss: 0.4659 - aux_output_loss: 1.0168 - val_loss: 0.5565 - val_main_output_loss: 0.5023 - val_aux_output_loss: 1.0445\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5158 - main_output_loss: 0.4620 - aux_output_loss: 1.0003 - val_loss: 0.5529 - val_main_output_loss: 0.5000 - val_aux_output_loss: 1.0289\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5112 - main_output_loss: 0.4587 - aux_output_loss: 0.9844 - val_loss: 0.5471 - val_main_output_loss: 0.4953 - val_aux_output_loss: 1.0128\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5068 - main_output_loss: 0.4555 - aux_output_loss: 0.9684 - val_loss: 0.5445 - val_main_output_loss: 0.4942 - val_aux_output_loss: 0.9978\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5023 - main_output_loss: 0.4523 - aux_output_loss: 0.9524 - val_loss: 0.5380 - val_main_output_loss: 0.4886 - val_aux_output_loss: 0.9829\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4988 - main_output_loss: 0.4500 - aux_output_loss: 0.9379 - val_loss: 0.5343 - val_main_output_loss: 0.4861 - val_aux_output_loss: 0.9681\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4947 - main_output_loss: 0.4471 - aux_output_loss: 0.9231 - val_loss: 0.5317 - val_main_output_loss: 0.4848 - val_aux_output_loss: 0.9537\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4915 - main_output_loss: 0.4452 - aux_output_loss: 0.9083 - val_loss: 0.5286 - val_main_output_loss: 0.4828 - val_aux_output_loss: 0.9404\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4876 - main_output_loss: 0.4424 - aux_output_loss: 0.8949 - val_loss: 0.5299 - val_main_output_loss: 0.4857 - val_aux_output_loss: 0.9274\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4852 - main_output_loss: 0.4412 - aux_output_loss: 0.8811 - val_loss: 0.5239 - val_main_output_loss: 0.4805 - val_aux_output_loss: 0.9146\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4821 - main_output_loss: 0.4392 - aux_output_loss: 0.8680 - val_loss: 0.5220 - val_main_output_loss: 0.4797 - val_aux_output_loss: 0.9024\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4791 - main_output_loss: 0.4373 - aux_output_loss: 0.8551 - val_loss: 0.5207 - val_main_output_loss: 0.4796 - val_aux_output_loss: 0.8909\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4761 - main_output_loss: 0.4353 - aux_output_loss: 0.8431 - val_loss: 0.5161 - val_main_output_loss: 0.4758 - val_aux_output_loss: 0.8789\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4734 - main_output_loss: 0.4337 - aux_output_loss: 0.8306 - val_loss: 0.5134 - val_main_output_loss: 0.4741 - val_aux_output_loss: 0.8675\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4712 - main_output_loss: 0.4326 - aux_output_loss: 0.8186 - val_loss: 0.5118 - val_main_output_loss: 0.4734 - val_aux_output_loss: 0.8570\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4686 - main_output_loss: 0.4310 - aux_output_loss: 0.8068 - val_loss: 0.5103 - val_main_output_loss: 0.4730 - val_aux_output_loss: 0.8469\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4661 - main_output_loss: 0.4295 - aux_output_loss: 0.7956 - val_loss: 0.5098 - val_main_output_loss: 0.4735 - val_aux_output_loss: 0.8369\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4641 - main_output_loss: 0.4285 - aux_output_loss: 0.7850 - val_loss: 0.5099 - val_main_output_loss: 0.4745 - val_aux_output_loss: 0.8285\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4619 - main_output_loss: 0.4271 - aux_output_loss: 0.7747 - val_loss: 0.5050 - val_main_output_loss: 0.4701 - val_aux_output_loss: 0.8186\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4598 - main_output_loss: 0.4258 - aux_output_loss: 0.7649 - val_loss: 0.5055 - val_main_output_loss: 0.4716 - val_aux_output_loss: 0.8104\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - main_output_loss: 0.4248 - aux_output_loss: 0.7549 - val_loss: 0.5060 - val_main_output_loss: 0.4730 - val_aux_output_loss: 0.8027\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4557 - main_output_loss: 0.4234 - aux_output_loss: 0.7459 - val_loss: 0.5036 - val_main_output_loss: 0.4712 - val_aux_output_loss: 0.7949\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4539 - main_output_loss: 0.4224 - aux_output_loss: 0.7368 - val_loss: 0.5005 - val_main_output_loss: 0.4686 - val_aux_output_loss: 0.7874\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4520 - main_output_loss: 0.4213 - aux_output_loss: 0.7285 - val_loss: 0.5001 - val_main_output_loss: 0.4689 - val_aux_output_loss: 0.7807\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4505 - main_output_loss: 0.4205 - aux_output_loss: 0.7205 - val_loss: 0.4990 - val_main_output_loss: 0.4684 - val_aux_output_loss: 0.7744\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4486 - main_output_loss: 0.4193 - aux_output_loss: 0.7124 - val_loss: 0.4980 - val_main_output_loss: 0.4679 - val_aux_output_loss: 0.7687\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4472 - main_output_loss: 0.4184 - aux_output_loss: 0.7059 - val_loss: 0.4975 - val_main_output_loss: 0.4680 - val_aux_output_loss: 0.7630\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4455 - main_output_loss: 0.4174 - aux_output_loss: 0.6984 - val_loss: 0.4988 - val_main_output_loss: 0.4699 - val_aux_output_loss: 0.7585\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4439 - main_output_loss: 0.4163 - aux_output_loss: 0.6919 - val_loss: 0.4950 - val_main_output_loss: 0.4664 - val_aux_output_loss: 0.7527\n"
     ]
    }
   ],
   "source": [
    "# since we didnt restart the model this is actually going til the 50th epoch\n",
    "history = model.fit(\n",
    "    {'wide_input': X_train_A, 'deep_input': X_train_B}, \n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=30, \n",
    "    validation_data=(\n",
    "        {'wide_input': X_valid_A, 'deep_input': X_valid_B}, \n",
    "        {'main_output': y_valid, 'aux_output': y_valid}\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5177 - main_output_loss: 0.4908 - aux_output_loss: 0.7599\n"
     ]
    }
   ],
   "source": [
    "# we have two losses now\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5177099108695984"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4907994568347931"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7599028944969177"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    }
   ],
   "source": [
    "# now have two predictions\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0599136],\n",
       "       [1.700481 ],\n",
       "       [2.0774426]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67476404],\n",
       "       [2.0080202 ],\n",
       "       [2.7493432 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOP Model Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this set up we use super() since it is a subclass of keras.models.Model so it inherits things like .fit(), .evaluate()...In the initialization we create our layers and in the call function we create the computations. This is very similar to the forward pass we did in the micrograd implementation. The method must be called call.\n",
    "\n",
    "**when using this technique, the dictionary naming of inputs and outputs does not work, use a tuple.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This added flexiblility includes putting for loops or other operations in the call method but we cannot save or clone it and the summary() method only shows the list of layers so stick to functional if you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        # keras has an output attribute so rename main_output\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0047 - output_1_loss: 1.8954 - output_2_loss: 2.9883 - val_loss: 1.0551 - val_output_1_loss: 0.9474 - val_output_2_loss: 2.0241\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8979 - output_1_loss: 0.7998 - output_2_loss: 1.7806 - val_loss: 0.7942 - val_output_1_loss: 0.7163 - val_output_2_loss: 1.4956\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7122 - output_1_loss: 0.6397 - output_2_loss: 1.3643 - val_loss: 0.7286 - val_output_1_loss: 0.6697 - val_output_2_loss: 1.2590\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6511 - output_1_loss: 0.5917 - output_2_loss: 1.1852 - val_loss: 0.6821 - val_output_1_loss: 0.6291 - val_output_2_loss: 1.1595\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6111 - output_1_loss: 0.5574 - output_2_loss: 1.0941 - val_loss: 0.6496 - val_output_1_loss: 0.5995 - val_output_2_loss: 1.1007\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5812 - output_1_loss: 0.5305 - output_2_loss: 1.0375 - val_loss: 0.6213 - val_output_1_loss: 0.5726 - val_output_2_loss: 1.0596\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5579 - output_1_loss: 0.5094 - output_2_loss: 0.9950 - val_loss: 0.6019 - val_output_1_loss: 0.5546 - val_output_2_loss: 1.0273\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5395 - output_1_loss: 0.4926 - output_2_loss: 0.9617 - val_loss: 0.5858 - val_output_1_loss: 0.5400 - val_output_2_loss: 0.9980\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5250 - output_1_loss: 0.4796 - output_2_loss: 0.9330 - val_loss: 0.5708 - val_output_1_loss: 0.5263 - val_output_2_loss: 0.9713\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5132 - output_1_loss: 0.4694 - output_2_loss: 0.9070 - val_loss: 0.5623 - val_output_1_loss: 0.5192 - val_output_2_loss: 0.9504\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-3), loss = ['mse', 'mse'], loss_weights=[0.9, 0.1])\n",
    "\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Restoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember this only works with the sequential or functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.7118 - val_loss: 0.8984\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7521 - val_loss: 0.6765\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6540 - val_loss: 0.6435\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6215 - val_loss: 0.6238\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5979 - val_loss: 0.6033\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5773 - val_loss: 0.5860\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5594 - val_loss: 0.5697\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5435 - val_loss: 0.5611\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.5458\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5153 - val_loss: 0.5362\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5032 - val_loss: 0.5263\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4924 - val_loss: 0.5194\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4833 - val_loss: 0.5109\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4751 - val_loss: 0.5051\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4679 - val_loss: 0.4994\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4969\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4914\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4507 - val_loss: 0.4871\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4851\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.4804\n",
      "162/162 [==============================] - 0s 922us/step - loss: 0.4995\n"
     ]
    }
   ],
   "source": [
    "# make a sequential model to be saved\n",
    "\n",
    "# when using input_shape batch size comes first so we start at 1\n",
    "# same as input_shape = [8] because X_train has 8 features\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = keras.optimizers.SGD(1e-3), loss = 'mse')\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022296201CF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 212ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.95043904],\n",
       "       [1.4848106 ],\n",
       "       [2.608714  ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions from saved model\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times training can last a long time so we should not only save the model at the end of training but also save checkpoints at regular intervals during training just incase the computer crashes. We should also tell the fit() method to save checkpoints. This is done using callbacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4385\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4353\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4323\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4297\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4246\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4227\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4206\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4185\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4168\n"
     ]
    }
   ],
   "source": [
    "# create callback\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "\n",
    "# this model will be saved at the end of each epoch\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent training for too long and overfitting we can use early stopping. This is done with save_best_only = True. The model will still train for all epochs but not every epoch will be saved (unless it gets better each time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4150 - val_loss: 0.4596\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4136 - val_loss: 0.4583\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4119 - val_loss: 0.4570\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4102 - val_loss: 0.4567\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4091 - val_loss: 0.4552\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4076 - val_loss: 0.4536\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4061 - val_loss: 0.4535\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4050 - val_loss: 0.4508\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4035 - val_loss: 0.4516\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.4500\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4011 - val_loss: 0.4491\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4001 - val_loss: 0.4483\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3991 - val_loss: 0.4479\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4469\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3968 - val_loss: 0.4454\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3959 - val_loss: 0.4450\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3948 - val_loss: 0.4449\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.4436\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3929 - val_loss: 0.4432\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3920 - val_loss: 0.4424\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be combined with the early stopping callback which interrupts training when it measures no progress on the validation data after a certain number of \"patience\" rounds. When we say patience = 5 it will go for 5 more epochs to check for an improvement. The restore best weights argument means after those 5 that did not improve we will go back to the one where it was improving.\n",
    "\n",
    "The following code combines both callbacks. Early stopping is used so that we do not train for 100 epochs if we do not have to and the old callback saves the best model. We did 56 epochs instead of 100 since we used early stopping. It is important to know that since we used save_best_only = True, the last epoch may not be the one that gets saved. This is because we do 5 patience rounds so the old callback already saved that model before training did not improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4420\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4414\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4397\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3886 - val_loss: 0.4399\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3877 - val_loss: 0.4394\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4399\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3862 - val_loss: 0.4372\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3854 - val_loss: 0.4386\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4372\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.4370\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3833 - val_loss: 0.4377\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4360\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4350\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4346\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4354\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3801 - val_loss: 0.4334\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3794 - val_loss: 0.4356\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3793 - val_loss: 0.4327\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4345\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3780 - val_loss: 0.4330\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3771 - val_loss: 0.4328\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3763 - val_loss: 0.4330\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.4322\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.4315\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3749 - val_loss: 0.4317\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 0.4342\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4319\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3733 - val_loss: 0.4306\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.4313\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4298\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3715 - val_loss: 0.4327\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4304\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4286\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3705 - val_loss: 0.4290\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3700 - val_loss: 0.4291\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3697 - val_loss: 0.4285\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.4283\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.4290\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3685 - val_loss: 0.4280\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.4281\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3673 - val_loss: 0.4291\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3671 - val_loss: 0.4282\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3667 - val_loss: 0.4281\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3665 - val_loss: 0.4276\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4266\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3654 - val_loss: 0.4278\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.4262\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4266\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.4261\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.4288\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3642 - val_loss: 0.4260\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.4262\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.4274\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3625 - val_loss: 0.4263\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.4265\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.4262\n"
     ]
    }
   ],
   "source": [
    "# early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make a class to implement a custom callback. This custom callback keeps track of the ratio between the training and validation error to detect overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f\"\\nval/train: {logs['val_loss'] / logs['loss']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/363 [..............................] - ETA: 2s - loss: 0.2624WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0003s vs `on_train_batch_begin` time: 0.0005s). Check your callbacks.\n",
      "318/363 [=========================>....] - ETA: 0s - loss: 0.3597\n",
      "val/train: 1.17\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.4250\n",
      "Epoch 2/5\n",
      "315/363 [=========================>....] - ETA: 0s - loss: 0.3585\n",
      "val/train: 1.18\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4264\n",
      "Epoch 3/5\n",
      "324/363 [=========================>....] - ETA: 0s - loss: 0.3615\n",
      "val/train: 1.17\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.4247\n",
      "Epoch 4/5\n",
      "293/363 [=======================>......] - ETA: 0s - loss: 0.3619\n",
      "val/train: 1.18\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.4261\n",
      "Epoch 5/5\n",
      "300/363 [=======================>......] - ETA: 0s - loss: 0.3603\n",
      "val/train: 1.17\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.4241\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=5,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use GridSearchCV or RandomizedSearchCV wrap the Keras models in objects that minim scikit-learn regressors. Create a function that will build and compile a Keras model given a set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build keras model\n",
    "def build_model(n_hidden = 1, n_neurons = 30, learning_rate = 1e-3, input_shape = [8]):\n",
    "    # create the model\n",
    "    model = keras.models.Sequential()\n",
    "    # create input layer\n",
    "    model.add(keras.layers.InputLayer(input_size=input_shape))\n",
    "\n",
    "    # for each hidden layer create the same architechure\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # compile\n",
    "    model.compile(loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
